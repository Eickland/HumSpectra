from typing import Callable, Dict, Sequence, Union, Optional, Mapping, Tuple, Any
from functools import wraps, lru_cache
import copy
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from scipy.optimize import curve_fit
from matplotlib.axes import Axes
from frozendict import frozendict
from scipy.signal import savgol_filter
import scipy.stats as st
from scipy.interpolate import CubicSpline
from tqdm import tqdm
from scipy.signal import find_peaks

import HumSpectra.utilits as ut

def read_mass_list(path: str,
                map_columns: dict|None = {"m/z":"mass","I":"intensity"},
                custom_columns_name: bool = False,
                sep: str|None = "\t",
                **kwargs) -> pd.DataFrame:
    """
    :param path: путь к файлу в строчном виде,
            (example: "C:/Users/mnbv2/Desktop/lab/KNP work directory/Флуоресценция/ADOM-SL2-1.csv").
    :param sep: разделитель в строчном виде (example: ",").
    :return: DataFrame: 
    """
    if sep is None:
        sep = ut.check_sep(path)
    try:
        data = pd.read_csv(path, sep=sep, **kwargs)
    except FileNotFoundError:
        raise FileNotFoundError(f"Файл не найден: {path}")
    except pd.errors.EmptyDataError:
        raise pd.errors.EmptyDataError(f"Файл пуст: {path}")
    except Exception as e:
        raise Exception(f"Ошибка при чтении файла: {e}")
    
    if custom_columns_name:
        data.rename(columns=map_columns,inplace=True)

        data = data[["mass","intensity"]]

    data.dropna(inplace=True, axis=1)
    data = data.astype("float64")
    name = ut.extract_name_from_path(path)
    data.attrs['name'] = name

    return data

def find_elements(self) -> Sequence[str]:
    """ 
    Find elements from columns of mass spectrum table.

    For example, column 'C' will be recognised as carbon 12C, column 'C_13" as 13C

    Returns
    -------
    list
    """

    main_elems = elements_table()['element'].values
    all_elems = elements_table()['element_isotop'].values

    elems = []
    for col in self.columns:
        if col in main_elems:
            elems.append(col)
        elif col in all_elems:
            elems.append(col)

    if len(elems) == 0:
        elems = ""

    self.attrs['elems'] = elems

    return elems

def _mark_assigned_by_brutto(self) -> None:
    """
    Mark peaks in loaded mass list if they have brutto

    Return
    ------
    Spectrum
    """

    assign = []
    elems = find_elements(self)
    for i, row in self.iterrows():
        flag = False
        for el in elems:
            if row[el] > 0:
                flag = True
        assign.append(flag) 
    self['assign'] = assign

def assign(data: pd.DataFrame,
            brutto_dict: Any|None = None,
            generated_bruttos_table: Optional[pd.DataFrame] = None,
            rel_error: float|None = None,
            abs_error: float|None = None,
            sign: str ='-',
            mass_min: Optional[float] =  None,
            mass_max: Optional[float] = None,
            intensity_min: Optional[float] =  None,
            intensity_max: Optional[float] = None,
            charge_max: int = 1,

    ) -> pd.DataFrame:
        """
        Assigning brutto formulas to signal by mass
        
        Parameters
        -----------
        brutto_dict: dict
            Optional. Deafault None.
            Custom Dictonary for generate brutto table.
            Example: {'C':(4, 51),'H':(4, 101),'O':(0,26), 'N':(0,4), 'C_13':(0,3)}
        generated_bruttos_table: pandas DataFrame 
            Optional. Contain column 'mass' and elements, 
            should be sorted by 'mass'.
            Can be generated by function brutto_generator.brutto_gen(). 
            if 'None' generate table with default elemnets and ranges
            C: 4-50, H 4-100, O 0-25, N 0-3, S 0-2.
        rel_error: float
            Optional. default 0.5, permissible error in ppm for assign mass to brutto formulas
        abs_error: float
            Optional. default None, permissible absolute error for assign mass to brutto formulas
        sign: str
            Optional. Deafult '-'.
            Mode in which mass spectrum was gotten. 
            '-' for negative mode
            '+' for positive mode
            '0' for neutral
        mass_min: float
            Optional. Default None. Minimall mass for assigment
        mass_max: float
            Optional. Default None. Maximum mass for assigment
        intensity_min: float
            Optional. Default None. Minimall intensity for assigment
        intensity_max: float
            Optional. Default None. Maximum intensity for assigment
        charge_max: int
            Maximum charge in m/z. Default 1.   

        Return
        ------
        pd.DataFrame 
        """

        name = data.attrs['name']

        if generated_bruttos_table is None:
            generated_bruttos_table = brutto_gen(brutto_dict)

        if mass_min is None:
            mass_min = data['mass'].min()
        if mass_max is None:
            mass_max = data['mass'].max()
        if intensity_min is None:
            intensity_min = data['intensity'].min()
        if intensity_max is None:
            intensity_max = data['intensity'].max()
        
        if sign == '-':
            mass_shift = - 0.00054858 + 1.007825  # electron and hydrogen mass
        elif sign == '+':
            mass_shift = 0.00054858  # electron mass
        elif sign == '0':
            mass_shift = 0
        else:
            raise Exception('Sended sign to assign method is not correct. May be "+","-","0"')

        data.attrs['sign'] = sign

        if rel_error is not None and abs_error is not None:
            raise Exception('one of rel_error or abs_error must be None in assign method')
        
        if rel_error is not None:
            rel = True
            
        elif abs_error is not None:
            rel = False
        else:
            rel = True
            rel_error = 0.5

        data = data.loc[:,['mass', 'intensity']].reset_index(drop=True)
        table = data.copy(deep=True)

        masses = np.array(generated_bruttos_table["mass"].values)

        elems = list(generated_bruttos_table.drop(columns=["mass"]))
        bruttos = generated_bruttos_table[elems].values.tolist()

        res = []
        for index, row in table.iterrows():

            if (row["mass"] < mass_min or 
                row["mass"] > mass_max or
                row["intensity"] < intensity_min or 
                row["intensity"] > intensity_max):
                res.append({"assign": False})
                continue 
            
            for charge in range(1, charge_max + 1):
                mass = (row["mass"] + mass_shift) * charge
                idx = np.searchsorted(masses, mass, side='left')
                if idx > 0 and (idx == len(masses) or np.fabs(mass - masses[idx - 1]) < np.fabs(mass - masses[idx])):
                    idx -= 1

                if rel:
                    if np.fabs(masses[idx] - mass) / mass * 1e6 <= rel_error/charge: # type: ignore
                        res.append({**dict(zip(elems, bruttos[idx])), "assign": True, "charge": charge})
                        break
                else:
                    if np.fabs(masses[idx] - mass) <= abs_error/charge: # type: ignore
                        res.append({**dict(zip(elems, bruttos[idx])), "assign": True, "charge": charge})
                        break
            else:
                res.append({"assign": False, "charge": 1})

        res = pd.DataFrame(res)

        table = table.join(res)
        data = data.merge(table, how='outer', on=list(data.columns))
        data['assign'] = data['assign'].fillna(False)
        data['charge'] = data['charge'].fillna(1)
        data.attrs['name'] = name

        return data

def _copy(func):
    """
    Decorator for deep copy pd.DataFrame before apllying methods
    
    Parameters
    ----------
    func: method
        function for decoarate
    
    Return
    ------
    function with deepcopyed pd.DataFrame
    """

    @wraps(func)
    def wrapper(dataframe, *args, **kwargs):
        # Создаем глубокую копию DataFrame
        dataframe_copy = copy.deepcopy(dataframe)
        
        # Вызываем оригинальную функцию с копией
        result = func(dataframe_copy, *args, **kwargs)
        
        return result
    
    return wrapper

@_copy
def noise_filter(self,
                    force: float = 1.5,
                    intensity: Optional[float] = None,
                    quantile: Optional[float] = None 
                    ) -> pd.DataFrame:
    """
    Remove noise from spectrum

    Parameters
    ----------
    intensity: float
        Cut by min intensity. 
        Default None and dont apply.
    quantile: float
        Cut by quantile. For example 0.1 mean that 10% 
        of peaks with minimal intensity will be cutted. 
        Default None and dont aplly
    force: float
        How many peaks should cut when auto-search noise level.
        Default 1.5 means that peaks with intensity more 
        than noise level*1.5 will be cutted
    
    Return
    ------
    pd.DataFrame

    Caution
    -------
    There is risk of loosing data. Do it cautiously.
    Level of noise may be determenided wrong. 
    Draw and watch spectrum.
    """
    
    if intensity is not None:
        self = self.loc[self['intensity'] > intensity].reset_index(drop=True)
        self.attrs['noise filter (intensity)'] = intensity
    
    elif quantile is not None:
        tresh = self['intensity'].quantile(quantile)
        self = self.loc[self['intensity'] > tresh].reset_index(drop=True)
        self.attrs['noise filter (quantile)'] = quantile
        
    
    else:

        intens = self['intensity'].values
        cut_diapasone=np.linspace(0, np.mean(intens),100)

        d = []
        for i in cut_diapasone:
            d.append(len(intens[intens > i]))

        dx = np.gradient(d, 1)
        tresh = np.where(dx==np.min(dx))
        cut = cut_diapasone[tresh[0][0]] * force
        self = self.loc[self['intensity'] > cut].reset_index(drop=True)

        self.attrs['noise filter (force)'] = force

    return self

@_copy
def drop_unassigned(self) -> "pd.DataFrame":
    """
    Drop unassigned by brutto rows

    Return
    ------
    pd.DataFrame

    Caution
    -------
    Danger of lose data - with these operation we exclude data that can be usefull
    """

    if "assign" not in self:
        raise Exception("Spectrum is not assigned")

    self = self.loc[self["assign"] == True].reset_index(drop=True)
    self.attrs['drop_unassigned'] = True

    return self

@_copy
def merge_duplicates(self) -> "pd.DataFrame":
    """
    merge duplicataes with the same calculated mass with sum intensity

    Return
    ------
    pd.DataFrame
    """
    if 'calc_mass' not in self.columns:
        self = calc_mass(self)

    cols = {col: ('sum' if col=='intensity' else 'max') for col in self.columns}
    self = self.groupby(['calc_mass'],as_index = False).agg(cols)
    return self

@_copy
def filter_by_C13(
    self, 
    rel_error: float = 0.5,
    remove: bool = False,
) -> pd.DataFrame:
    """ 
    Check if peaks have the same brutto with C13 isotope

    Parameters
    ----------
    rel_error: float
        Optional. Default 0.5.
        Allowable ppm error when checking c13 isotope peak
    remove: bool
        Optional, default False. 
        Drop unassigned peaks and peaks without C13 isotope
    
    Return
    ------
    pd.DataFrame
    """
    
    self = self.sort_values(by='mass').reset_index(drop=True)
    
    flags = np.zeros(self.shape[0], dtype=bool)
    masses = self["mass"].values
    
    C13_C12 = 1.003355  # C13 - C12 mass difference

    
    for index, row in self.iterrows():
        mass = row["mass"] + C13_C12
        error = mass * rel_error * 0.000001

        idx = np.searchsorted(masses, mass, side='left')
        
        if idx > 0 and (idx == len(masses) or np.fabs(mass - masses[idx - 1]) < np.fabs(mass - masses[idx])):
            idx -= 1
        
        if np.fabs(masses[idx] - mass)  <= error:
            flags[index] = True
    
    self['C13_peak'] = flags

    if remove:
        self = self.loc[(self['C13_peak'] == True) & (self['assign'] == True)].reset_index(drop=True)
        self.attrs['filter_C13'] = True
        

    return self

@_copy
def normalize(self, how:str='sum') -> pd.DataFrame:
    """
    Intensity normalize by intensity

    Parameters
    ----------
    how: {'sum', 'max', 'median', 'mean'}
        'sum' for normilize by sum of intensity of all peaks. (default)
        'max' for normilize by higher intensity peak.
        'median' for normilize by median of peaks intensity.
        'mean' for normilize by mean of peaks intensity.

    Return
    ------
    pd.DataFrame
    """

    if how=='max':
        self['intensity'] /= self['intensity'].max()
    elif how=='sum':
        self['intensity'] /= self['intensity'].sum()
    elif how=='median':
        self['intensity'] /= self['intensity'].median()
    elif how=='mean':
        self['intensity'] /= self['intensity'].mean()
    else:
        raise Exception(f"There is no such mode: {how}")
    
    self.attrs['normilize'] = how

    return self

@_copy
def merge_isotopes(self) -> "pd.DataFrame":
    """
    Merge isotopes.

    For example if specrum list have 'C' and 'C_13' they will be summed in 'C' column.

    Return
    ------
    pd.DataFrame

    Caution
    -------
    Danger of lose data - with these operation we exclude data that can be usefull       
    """

    elems = find_elements(self)
    for el in elems:
        res = el.split('_')
        if len(res) == 2:
            if res[0] not in self:
                self[res[0]] = 0
            self[res[0]] = self[res[0]] + self[el]
            self = self.drop(columns=[el])
    
    self.attrs['merge_isotopes'] = True

    return self

@_copy
def calc_mass(self,debug=False) -> pd.DataFrame:
    """
    Calculate mass from assigned brutto formulas and elements exact masses

    Add column "calc_mass" to self

    Return
    ------
    Spectrum
    """

    if "assign" not in self:
        raise Exception("Spectrum is not assigned")
    
    elems = find_elements(self)
    
    if debug:
        print(elems)
        print(self.loc[:,elems])
        
    table = self.loc[:,elems].copy(deep=True)
    
    masses = get_elements_masses(elems)

    self["calc_mass"] = table.multiply(masses).sum(axis=1)
    self["calc_mass"] = np.round(self["calc_mass"], 6)
    self.loc[self["calc_mass"] == 0, "calc_mass"] = np.nan

    return self

@_copy
def _calc_sign(self) -> str:
    """
    Determine sign from mass and calculated mass

    '-' for negative mode
    '+' for positive mode
    '0' for neutral

    Return
    ------
    str            
    """

    self = drop_unassigned(self)

    if "calc_mass" not in self:
        self = calc_mass(self)

    if "charge" not in self.columns:
        self["charge"] = 1

    value = (self["calc_mass"]/self["charge"] - self["mass"]).mean()
    value = np.round(value,4)
    if value > 1:
        return '-'
    elif value > 0.0004 and value < 0.01:
        return '+'
    else:
        return '0'

@_copy
def calc_error(self, sign: Optional[str] = None) -> pd.DataFrame:
    """
    Calculate relative and absolute error of assigned peaks from measured and calculated masses

    Add columns "abs_error" and "rel_error" to self

    Parameters
    ----------
    sign: {'-', '+', '0'}
        Optional. Default None and get from metatdata or calculated by self. 
        Mode in which mass spectrum was gotten. 
        '-' for negative mode
        '+' for positive mode
        '0' for neutral
    
    Return
    ------
    Spectrum
    """

    if "calc_mass" not in self:
        self = calc_mass(self)

    if "charge" not in self.columns:
        self["charge"] = 1

    if sign is None:
        if 'sign' in self.attrs:
            sign = self.attrs['sign']
        else:
            sign = _calc_sign(self)

    if sign == '-':
        self["abs_error"] = ((self["mass"] + (- 0.00054858 + 1.007825)) * self["charge"]) - self["calc_mass"] #-electron + proton
    elif sign == '+':
        self["abs_error"] = ((self["mass"] + 0.00054858) * self["charge"]) - self["calc_mass"]#+electron
    elif sign == '0':
        self["abs_error"] = (self["mass"] * self["charge"]) - self["calc_mass"]
    else:
        raise ValueError('Sended sign or sign in attrs is not correct. May be "+","-","0"')
    
    self["rel_error"] = self["abs_error"] / self["mass"] * 1e6
    
    return self

@_copy
def brutto(self) -> pd.DataFrame:
    """
    Calculate string with brutto from assign table

    Add column "britto" to self

    Return
    ------
    Spectrum
    """

    if "assign" not in self:
        raise Exception("Spectrum is not assigned")

    elems = find_elements(self)
    out = []
    for i, row in self.iterrows():
        s = ''
        for el in elems:
            if len(el.split('_')) == 2:
                ele = f'({el})'
            else:
                ele = el
            if row[el] == 1:
                s = s + f'{ele}'
            elif row[el] > 0:
                s = s + f'{ele}{int(row[el])}'
        out.append(s)
    
    self['brutto'] = out

    return self

@_copy
def cram(self) -> pd.DataFrame:
    """
    Mark rows that fit CRAM conditions
    (carboxylic-rich alicyclic molecules)

    Add column "CRAM" to self

    Return
    ------
    Spectrum

    References
    ----------
    Hertkorn, N. et al. Characterization of a major 
    refractory component of marine dissolved organic matter.
    Geochimica et. Cosmochimica Acta 70, 2990-3010 (2006)
    """

    if "DBE" not in self:
        self = dbe(self)        

    def check(row):
        if row['DBE']/row['C'] < 0.3 or row['DBE']/row['C'] > 0.68:
            return False
        if row['DBE']/row['H'] < 0.2 or row['DBE']/row['H'] > 0.95:
            return False
        if row['O'] == 0:
            return False
        elif row['DBE']/row['O'] < 0.77 or row['DBE']/row['O'] > 1.75:
            return False
        return True

    table = merge_isotopes(self.copy(deep=True))
    self['CRAM'] = table.apply(check, axis=1)

    return self

@_copy
def ai(self) -> pd.DataFrame:
    """
    Calculate AI (aromaticity index)

    Add column "AI" to self

    Return
    ------
    Spectrum

    References
    ----------
    Koch, Boris P., and T. Dittmar. "From mass to structure: An aromaticity 
    index for high resolution mass data of natural organic matter." 
    Rapid communications in mass spectrometry 20.5 (2006): 926-932.
    """

    if "DBE_AI" not in self:
        self = dbe_ai(self)

    if "CAI" not in self:
        self = cai(self)

    self["AI"] = self["DBE_AI"] / self["CAI"]

    clear  = self["AI"].values[np.isfinite(self["AI"].values.astype('float'))].astype('float')
    self['AI'] = self['AI'].replace(-np.inf, np.min(clear))
    self['AI'] = self['AI'].replace(np.inf, np.max(clear))
    self['AI'] = self['AI'].replace(np.nan, np.mean(clear))

    return self

@_copy
def cai(self) -> pd.DataFrame:
    """
    Calculate CAI (C - O - N - S - P)

    Add column "CAI" to self

    Return
    ------
    Spectrum
    """
    
    if "assign" not in self:
        raise Exception("Spectrum is not assigned")

    table = merge_isotopes(self)

    for element in "CONSP":
        if element not in table:
            table[element] = 0

    self['CAI'] = table["C"] - table["O"] - table["N"] - table["S"] - table["P"]

    return self

@_copy
def dbe_ai(self) -> pd.DataFrame:
    """
    Calculate DBE_AI (1 + C - O - S - 0.5 * (H + N + P))

    Add column "DBE_AI" to self

    Return
    ------
    Spectrum
    """

    if "assign" not in self:
        raise Exception("Spectrum is not assigned")

    table = merge_isotopes(self)

    for element in "CHONPS":
        if element not in table:
            table[element] = 0

    self['DBE_AI'] = 1.0 + table["C"] - table["O"] - table["S"] - 0.5 * (table["H"] + table['N'] + table["P"])

    return self

@_copy
def dbe(self) -> pd.DataFrame:
    """
    Calculate DBE (1 + C - 0.5 * (H + N))

    Add column "DBE" to self

    Return
    ------
    Spectrum
    """

    if "assign" not in self:
        raise Exception("Spectrum is not assigned")

    table = merge_isotopes(self)

    for element in "CHON":
        if element not in table:
            table[element] = 0

    self['DBE'] = 1.0 + table["C"] - 0.5 * (table["H"] - table['N'])

    return self

@_copy
def dbe_o(self) -> pd.DataFrame:
    """
    Calculate DBE - O

    Add column "DBE-O" to self

    Return
    ------
    Spectrum 
    """

    if "DBE" not in self:
        self = dbe(self)

    table = merge_isotopes(self)
    self['DBE-O'] = table['DBE'] - table['O']

    return self

@_copy
def dbe_oc(self) -> pd.DataFrame:
    """
    Calculate (DBE - O) / C

    Add column "DBE-OC" to self

    Return
    ------
    Spectrum
    """

    if "DBE" not in self:
        self = dbe(self)

    table = merge_isotopes(self)
    self['DBE-OC'] = (table['DBE'] - table['O'])/table['C']

    return self

@_copy
def hc_oc(self) -> pd.DataFrame:
    """
    Calculate H/C and O/C

    Add columns "H/C" and "O/C" to self

    Return
    ------
    Spectrum
    """

    if "assign" not in self:
        raise Exception("Spectrum is not assigned")

    table = merge_isotopes(self)
    self['H/C'] = table['H']/table['C']
    self['O/C'] = table['O']/table['C']

    return self

@_copy
def kendrick(self) -> pd.DataFrame:
    """
    Calculate Kendrick mass and Kendrick mass defect

    Add columns "Ke" and 'KMD" to self

    Return
    ------
    Spectrum
    """

    if 'calc_mass' not in self:
        self = calc_mass(self)

    self['Ke'] = self['calc_mass'] * 14/14.01565
    self['KMD'] = np.floor(self['calc_mass'].values.astype('float')) - np.array(self['Ke'].values)
    self.loc[self['KMD']<=0, 'KMD'] = self.loc[self['KMD']<=0, 'KMD'] + 1

    return self

@_copy
def nosc(self) -> pd.DataFrame:
    """
    Calculate Normal oxidation state of carbon (NOSC)

    Add column "NOSC" to self

    Notes
    -----
    >0 - oxidate state.
    <0 - reduce state.
    0 - neutral state

    References
    ----------
    Boye, Kristin, et al. "Thermodynamically 
    controlled preservation of organic carbon 
    in floodplains."
    Nature Geoscience 10.6 (2017): 415-419.

    Return
    ------
    Spectrum
    """

    if "assign" not in self:
        raise Exception("Spectrum is not assigned")

    table = merge_isotopes(self)

    for element in "CHONS":
        if element not in table:
            table[element] = 0

    self['NOSC'] = 4.0 - (table["C"] * 4 + table["H"] - table['O'] * 2 - table['N'] * 3 - table['S'] * 2)/table['C']

    return self

@_copy
def mol_class(self, how: Optional[str] = None) -> pd.DataFrame:
    """
    Assign molecular class for formulas

    Add column "class" to self

    Parameters
    ----------
    how: {'kellerman', 'perminova', 'laszakovits'}
        How devide to calsses. Optional. Default 'laszakovits'

    Return
    ------
    Spectrum

    References
    ----------
    Laszakovits, J. R., & MacKay, A. A. Journal of the American Society for Mass Spectrometry, 2021, 33(1), 198-202.
    A. M. Kellerman, T. Dittmar, D. N. Kothawala, L. J. Tranvik. Nat. Commun. 2014, 5, 3804
    Perminova I. V. Pure and Applied Chemistry. 2019. Vol. 91, № 5. P. 851-864
    """

    if 'AI' not in self:
        self = ai(self)
    if 'H/C' not in self or 'O/C' not in self:
        self = hc_oc(self)

    table = merge_isotopes(self)

    for element in "CHON":
        if element not in table:
            table[element] = 0

    def get_zone_kell(row):

        if row['H/C'] >= 1.5:
            if row['O/C'] < 0.3 and row['N'] == 0:
                return 'lipids'
            elif row['N'] >= 1:
                return 'N-satureted'
            else:
                return 'aliphatics'
        elif row['H/C'] < 1.5 and row['AI'] < 0.5:
            if row['O/C'] <= 0.5:
                return 'unsat_lowOC'
            else:
                return 'unsat_highOC'
        elif row['AI'] > 0.5 and row['AI'] <= 0.67:
            if row['O/C'] <= 0.5:
                return 'aromatic_lowOC'
            else:
                return 'aromatic_highOC'
        elif row['AI'] > 0.67:
            if row['O/C'] <= 0.5:
                return 'condensed_lowOC'
            else:
                return 'condensed_highOC'
        else:
            return 'undefinded'
    
    def get_zone_perm(row):

        if row['O/C'] < 0.5:
            if row['H/C'] < 1:
                return 'condensed_tanins'
            elif row['H/C'] < 1.4:
                return 'phenylisopropanoids'
            elif row['H/C'] < 1.8:
                return 'terpenoids'
            elif row['H/C'] <= 2.2:
                if row['O/C'] < 0.25:
                    return 'lipids'
                else:
                    return 'proteins'
            else:
                return 'undefinded'
        elif row['O/C'] <= 1:
            if row['H/C'] < 1.4:
                return 'hydrolyzable_tanins'
            elif row['H/C'] <= 2.2:
                return 'carbohydrates'
            else:
                return 'undefinded'
        else:
            return 'undefinded'

    def get_zone_lasz(row):
        if row['H/C'] >= 0.86 and row['H/C'] <=1.34 and row['O/C'] >= 0.21 and row['O/C'] <=0.44:
            return 'lignin'
        elif row['H/C'] >= 0.7 and row['H/C'] <=1.01 and row['O/C'] >= 0.16 and row['O/C'] <=0.84:
            return 'tannin'
        elif row['H/C'] >= 1.33 and row['H/C'] <=1.84 and row['O/C'] >= 0.17 and row['O/C'] <=0.48:
            return 'peptide'
        elif row['H/C'] >= 1.34 and row['H/C'] <=2.18 and row['O/C'] >= 0.01 and row['O/C'] <=0.35:
            return 'lipid'
        elif row['H/C'] >= 1.53 and row['H/C'] <=2.2 and row['O/C'] >= 0.56 and row['O/C'] <=1.23:
            return 'carbohydrate'
        elif row['H/C'] >= 1.62 and row['H/C'] <=2.35 and row['O/C'] >= 0.56 and row['O/C'] <=0.95:
            return 'aminosugar'
        else:
            return 'undefinded'
    
    if how == 'perminova':
        self['class'] = table.apply(get_zone_perm, axis=1)
    elif how == 'kellerman':
        self['class'] = table.apply(get_zone_kell, axis=1)
    else:
        self['class'] = table.apply(get_zone_lasz, axis=1)

    return self

@_copy
def get_mol_class(self, how_average: str = "weight", how: Optional[str] = None) -> pd.DataFrame:
    """
    get molercular class density

    Parameters
    ----------
    how_average: {'weight', 'count'}
        how average density. Default "weight" - weight by intensity.
        Also can be "count".
    how: {'kellerman', 'perminova', 'laszakovits'}
        How devide to calsses. Optional. Default 'laszakovits'

    Return
    ------
    pandas Dataframe
    
    References
    ----------
    Laszakovits, J. R., & MacKay, A. A. Journal of the American Society for Mass Spectrometry, 2021, 33(1), 198-202.
    A. M. Kellerman, T. Dittmar, D. N. Kothawala, L. J. Tranvik. Nat. Commun. 5, 3804 (2014)
    Perminova I. V. Pure and Applied Chemistry. 2019. Vol. 91, № 5. P. 851-864
    """

    self = mol_class(drop_unassigned(self),how=how)
    count_density = len(self)
    sum_density = self["intensity"].sum()

    out = []

    if how == 'perminova':
        zones = ['condensed_tanins',
                'hydrolyzable_tanins',
                'phenylisopropanoids',
                'terpenoids',
                'lipids',
                'proteins',
                'carbohydrates',
                'undefinded']
    elif how == 'kellerman':
        zones = ['unsat_lowOC',
                'unsat_highOC',
                'condensed_lowOC',
                'condensed_highOC',
                'aromatic_lowOC',
                'aromatic_highOC',
                'aliphatics',            
                'lipids',
                'N-satureted',
                'undefinded']
    else:
        zones = ['aminosugar',
                'carbohydrate',
                'lignin',
                'lipid',
                'peptide',
                'tannin',
                'undefinded']


    for zone in zones:

        if how_average == "count":
            out.append([zone, len(self.loc[self['class'] == zone])/count_density])

        elif how_average == "weight":
            out.append([zone, self.loc[self['class'] == zone, 'intensity'].sum()/sum_density])

        else:
            raise ValueError(f"how_average should be count or intensity not {how_average}")
    
    return pd.DataFrame(data=out, columns=['class', 'density'])

@_copy
def get_dbe_vs_o(self, 
                    olim: Optional[Tuple[int, int]] = None, 
                    draw: bool = True, 
                    ax: Union[Axes, None] = None, 
                    **kwargs) -> Tuple[float, float]:
    """
    Calculate DBE vs nO by linear fit
    
    Parameters
    ----------
    olim: tuple of two int
        limit for nO. Deafult None
    draw: bool
        draw scatter DBE vs nO and how it is fitted
    ax: matplotlib axes
        ax fo outer plot. Default None
    **kwargs: dict
        dict for additional condition to scatter matplotlib

    Return
    ------
    (float, float)
        a and b in fit DBE = a * nO + b

    References
    ----------
    Bae, E., Yeo, I. J., Jeong, B., Shin, Y., Shin, K. H., & Kim, S. (2011). 
    Study of double bond equivalents and the numbers of carbon and oxygen 
    atom distribution of dissolved organic matter with negative-mode FT-ICR MS.
    Analytical chemistry, 83(11), 4193-4199.
    """

    if 'DBE' not in self:
        self = dbe(self)
    
    self = drop_unassigned(self)
    if olim is None:
        no = list(range(int(self['O'].min())+5, int(self['O'].max())-5))
    else:
        no = list(range(olim[0],olim[1]))
    
    dbe_o = []
    
    for i in no:
        dbes = self.loc[self['O'] == i, 'DBE']
        intens = self.loc[self['O'] == i, 'intensity']
        dbe_o.append((dbes*intens).sum()/intens.sum())

    def linear(x, a, b):
        return a*x + b

    x = np.array(no)
    y = np.array(dbe_o)

    popt, pcov = curve_fit(linear, x, y)
    residuals = y- linear(x, *popt)
    ss_res = np.sum(residuals**2)
    ss_tot = np.sum((y-np.mean(y))**2)
    r_squared = 1 - (ss_res / ss_tot)
    
    if draw:
        if ax is None:
            fig,ax = plt.subplots(figsize=(3,3), dpi=100)
        
        ax.scatter(x, y, **kwargs)
        ax.plot(x, linear(x, *popt), label=f'y={round(popt[0],2)}x + {round(popt[1],1)} R2={round(r_squared, 4)}', **kwargs)
        ax.set_xlim(4)
        ax.set_ylim(5)
        ax.set_xlabel('number of oxygen')
        ax.set_ylabel('DBE average')
        ax.legend()

    return popt[0], popt[1]

@_copy
def get_squares_vk(self,
                    how_average: str = 'weight',
                    ax: Union[Axes, None] = None, 
                    draw: bool = False) -> pd.DataFrame:
    """
    Calculate density in Van Krevelen diagram divided into 20 squares

    Squares index in Van-Krevelen diagram if H/C is rows, O/C is columns:
    [[5, 10, 15, 20],
        [4, 9, 14, 19],
        [3, 8, 13, 18],
        [2, 7, 12, 17],
        [1, 6, 11, 16]]

    H/C divided by [0-0.6, 0.6-1, 1-1.4, 1.4-1.8, 1.8-2.2]
    O/C divided by [0-0.25, 0.25-0.5, 0.5-0.75, 0.75-1.0]

    Parameters
    ----------
    how_average: {'weight', 'count'}
        How calculate average. My be "count" or "weight" (default)
    ax: matplotlib ax
        Optional. external ax
    draw: bool
        Optional. Default False. Plot heatmap

    Return
    ------
    Pandas Dataframe

    References
    ----------
    Perminova I. V. From green chemistry and nature-like technologies towards 
    ecoadaptive chemistry and technology // Pure and Applied Chemistry. 
    2019. Vol. 91, № 5. P. 851-864.
    """

    if 'H/C' not in self or 'O/C' not in self:
        self = drop_unassigned(hc_oc(self))

    d_table = []
    sq = []

    for y in [ (1.8, 2.2), (1.4, 1.8), (1, 1.4), (0.6, 1), (0, 0.6)]:
        hc = []
        for x in  [(0, 0.25), (0.25, 0.5), (0.5, 0.75), (0.75, 1)]:
            temp = self.copy(deep=True)
            temp = temp.loc[(temp['O/C'] >= x[0]) & (temp['O/C'] < x[1]) & (temp['H/C'] >= y[0]) & (temp['H/C'] < y[1])]

            if how_average == 'count':
                res = len(temp)/len(self)
                hc.append(res)
                sq.append(res)
            elif how_average == 'weight':
                res = temp['intensity'].sum()/self['intensity'].sum()
                hc.append(res)
                sq.append(res)
        d_table.append(hc)

    out = pd.DataFrame(data = d_table, columns=['0-0.25', '0,25-0.5','0.5-0.75','0.75-1'], index=['1.8-2.2', '1.4-1.8', '1-1.4', '0.6-1', '0-0.6'])

    if draw:
        if ax is None:
            fig, ax = plt.subplots(figsize=(4, 4), dpi=75)
        sns.heatmap(out.round(4),cmap='coolwarm',annot=True, linewidths=.5, ax=ax)
        bottom, top = ax.get_ylim()
        plt.yticks(rotation=0)
        plt.xticks(rotation=90) 
        ax.set_ylim(bottom + 0.5, top - 0.5)

        ax.set_xlabel('O/C')
        ax.set_ylabel('H/C')

    # just for proper naming of squars. bad solution
    square = pd.DataFrame()
    square['value'] = sq
    square['square'] = [5,10,15,20,   4,9,14,19,   3,8,13,18,    2,7,12,17,   1,6,11,16]
    
    return square.sort_values(by='square').reset_index(drop=True)

@_copy
def get_mol_metrics(self, 
                    metrics: set[str], 
                    func: Optional[str] = None) -> pd.DataFrame:
    """
    Get average metrics

    Parameters
    ----------
    metrics: Sequence[str]
        Optional. Default None. Chose metrics fot watch.
    func: {'weight', 'mean', 'median', 'max', 'min', 'std'}
        How calculate average. My be "weight" (default - weight average on intensity),
        "mean", "median", "max", "min", "std" (standard deviation)

    Return
    ------
    pandas DataFrame
    """

    #self = self.calc_all_metrics().drop_unassigned().normalize()
    self = normalize(
        drop_unassigned(
            calc_all_metrics(self)
            )
            )

    if metrics is None:
        metrics = set(self.columns) - set(['intensity', 'calc_mass', 'rel_error','abs_error',
                                                'assign', 'charge', 'class', 'brutto', 'Ke', 'KMD'])

    res = []
    sorted_metrics = np.sort(np.array(list(metrics)))

    if func is None:
        func = 'weight'

    func_dict = {'mean': lambda col : np.average(self[col]),
                'weight': lambda col : np.average(self[col], weights=self['intensity']),
                'median': lambda col : np.median(self[col]),
                'max': lambda col : np.max(self[col]),
                'min': lambda col : np.min(self[col]),
                'std': lambda col : np.std(self[col])}
    if func not in func_dict:
        raise ValueError(f'not correct value - {func}')
    else:
        f = func_dict[func]

    for col in sorted_metrics:
        try:
            res.append([col, f(col)])
        except:
            res.append([col, np.nan])

    return pd.DataFrame(data=res, columns=['metric', 'value'])

@_copy
def calc_all_metrics(self) -> pd.DataFrame:
    """
    Calculated all available metrics

    Return
    ------
    Spectrum
    """

    self = calc_mass(self)
    self = calc_error(self)
    self = dbe(self)
    self = dbe_o(self)
    self = ai(self)
    self = dbe_oc(self)
    self = dbe_ai(self)
    self = mol_class(self)
    self = hc_oc(self)
    self = cai(self)
    self = cram(self)
    self = nosc(self)
    self = brutto(self)
    self = kendrick(self)

    return self

def _freeze(func):
    """
    freeze dict in func
    """
    @wraps(func)
    def wrapped(*args, **kwargs):
        args = tuple([frozendict(arg) if isinstance(arg, dict) else arg for arg in args])
        kwargs = {k: frozendict(v) if isinstance(v, dict) else v for k, v in kwargs.items()}
        return func(*args, **kwargs)
    return wrapped

def _process_elems(elems: Any) -> Dict[str, Tuple[int, int]]:
    """
    Преобразует входные данные в рабочий dict
    """

    if elems is None:
        return {'C':(4, 51),'H':(4, 101),'O':(0,26), 'N':(0,4), 'S':(0,3)}
    elif isinstance(elems, frozendict):
        return dict(elems)
    elif isinstance(elems, dict):
        return elems
    else:
        raise TypeError(f"Expected dict, frozendict or None, got {type(elems)}")

@_freeze
@lru_cache(maxsize=None)
def brutto_gen(elems: Optional[Dict[str, Tuple[int, int]]] = None, rules: bool = True) -> pd.DataFrame:
    """
    Generete brutto formula dataframe

    Parameters
    ----------
    elems: dict
        Dictonary with elements and their range for generate brutto table 
        Example: {'C':(1,60),'O_18':(0,3)} - content of carbon (main isotope) from 1 to 59,
        conent of isotope 18 oxygen from 0 to 2. 
        By default it is {'C':(4, 51),'H':(4, 101),'O':(0,26), 'N':(0,4), 'S':(0,3)}
    rules: bool
        Rules: 0.25<H/C<2.2, O/C < 1, nitogen parity, DBE-O <= 10. 
        By default it is on, but for tmds should be off

    Returns
    -------
    pandas Dataframe
        Dataframe with masses for elements content
    """

    working_elems = _process_elems(elems)

    #load elements table. Generatete in mass folder
    elems_mass_table = elements_table()
    elems_arr = []
    elems_dict = {}
    for el in working_elems:
        elems_arr.append(np.array(range(working_elems[el][0],working_elems[el][1])))
        if '_' not in el:
            temp = elems_mass_table.loc[elems_mass_table['element']==el].sort_values(by='abundance',ascending=False).reset_index(drop=True)
            elems_dict[el] = temp.loc[0,'mass']
        else:
            temp = elems_mass_table.loc[elems_mass_table['element_isotop']==el].reset_index(drop=True)
            elems_dict[el] = temp.loc[0,'mass']

    #generate grid with all possible combination of elements in their ranges
    t = np.array(np.meshgrid(*elems_arr)).T.reshape(-1,len(elems_arr))
    gdf = pd.DataFrame(t,columns=list(elems_dict.keys()))
    #do rules H/C, O/C, and parity
    if rules:
       gdf = filter_by_rules(gdf)

    #calculate mass
    masses = np.array(list(elems_dict.values()))
    gdf['mass'] = gdf.multiply(masses).sum(axis=1)
    gdf['mass'] = np.round(gdf['mass'], 6)

    gdf = gdf.sort_values("mass").reset_index(drop=True)

    return gdf

def filter_by_rules(gdf: pd.DataFrame) -> pd.DataFrame:
    
    data = copy.deepcopy(gdf)
    temp = copy.deepcopy(data)
    temp=_merge_isotopes(temp)

    if 'C' not in temp or 'H' not in temp or 'O' not in temp:
        raise Exception('For applying rules in brutto must be CHO elements or their isotopes')
        
    temp['H/C'] = temp['H']/temp['C']
    temp['O/C'] = temp['O']/temp['C']
    data = data.loc[(temp['H/C'] < 2.2) & (temp['H/C'] > 0.25) & (temp['O/C'] < 1)]

    if 'N' not in temp:
        temp['N'] = 0
        
    temp['DBE-O'] = 1.0 + temp["C"] - 0.5 * temp["H"] + 0.5 * temp['N'] - temp['O']
    data = data.loc[temp['DBE-O'] <= 10]
        
    if 'N' in temp:
        temp['parity'] = (temp['H'] + temp['N'])%2
        data = data.loc[temp['parity']==0]
    
    return data

def _merge_isotopes(gdf: pd.DataFrame) -> pd.DataFrame:
    """
    All isotopes will be merged and title as main.

    Return
    ------
    pandas Dataframe    
    """

    for el in gdf.columns:
        res = el.split('_')
        if len(res) == 2:
            if res[0] not in gdf:
                gdf[res[0]] = 0
            gdf[res[0]] = gdf[res[0]] + gdf[el]
            gdf = gdf.drop(columns=[el]) 

    return gdf

def get_elements_masses(elems: Sequence[str]) -> np.ndarray :
    """
    Get elements masses from list

    Parameters
    ----------
    elems: Sequence[str]
        List of elements. Example: ['C', 'H', 'N', 'C_13', 'O']

    Return
    ------
    numpy array
    """
    
    elements = elements_table()    
    elems_masses = []

    for el in elems:
        if '_' not in el:
            temp = elements.loc[elements['element']==el].sort_values(by='abundance',ascending=False).reset_index(drop=True)
            elems_masses.append(temp.loc[0,'mass'])
        else:
            temp = elements.loc[elements['element_isotop']==el].reset_index(drop=True)
            elems_masses.append(temp.loc[0,'mass'])

    return np.array(elems_masses)

def gen_from_brutto(table: pd.DataFrame) -> pd.DataFrame:
    """
    Generate mass from brutto table

    Parameters
    ----------
    table: pandas Dataframe
        table with elemnt contnent

    Return
    ------
    pandas DataFrame
        Dataframe with elements and masses
    """
    masses = get_elements_masses(table.columns.to_list())

    table["calc_mass"] = table.multiply(masses).sum(axis=1)
    table["calc_mass"] = np.round(table["calc_mass"], 6)
    table.loc[table["calc_mass"] == 0, "calc_mass"] = np.nan

    return table

def elements_table() -> pd.DataFrame: 
    """
    Table with exact mass of element and their isotop abundance

    Return
    ------
    Pandas DataFrame 
        Dataframe with exact mass of element and their isotop abundance
    """

    return pd.DataFrame(
    columns = ['element', 'mass', 'abundance', 'isotop', 'element_isotop'],
        data = [["Al", 26.981538, 100.0, 27, "Al_27"],
                ["Sb", 120.903818, 57.21, 121, "Sb_121"],
                ["Sb", 122.904216, 42.79, 123, "Sb_123"],
                ["Ar", 35.967546, 0.3365, 36, "Ar_36"],
                ["Ar", 37.962732, 0.0632, 38, "Ar_38"],
                ["Ar", 39.962383, 99.6003, 40, "Ar_40"],
                ["As", 74.921596, 100.0, 75, "As_75"],
                ["Ba", 129.90631, 0.106, 130, "Ba_130"],
                ["Ba", 131.905056, 0.101, 132, "Ba_132"],
                ["Ba", 133.904503, 2.417, 134, "Ba_134"],
                ["Ba", 134.905683, 6.592, 135, "Ba_135"],
                ["Ba", 135.90457, 7.854, 136, "Ba_136"],
                ["Ba", 136.905821, 11.232, 137, "Ba_137"],
                ["Ba", 137.905241, 71.698, 138, "Ba_138"],
                ["Be", 9.012182, 100.0, 9, "Be_9"],
                ["Bi", 208.980383, 100.0, 209, "Bi_209"],
                ["B", 10.012937, 19.9, 10, "B_10"],
                ["B", 11.009305, 80.1, 11, "B_11"],
                ["Br", 78.918338, 50.69, 79, "Br_79"],
                ["Br", 80.916291, 49.31, 81, "Br_81"],
                ["Cd", 105.906458, 1.25, 106, "Cd_106"],
                ["Cd", 107.904183, 0.89, 108, "Cd_108"],
                ["Cd", 109.903006, 12.49, 110, "Cd_110"],
                ["Cd", 110.904182, 12.8, 111, "Cd_111"],
                ["Cd", 111.902757, 24.13, 112, "Cd_112"],
                ["Cd", 112.904401, 12.22, 113, "Cd_113"],
                ["Cd", 113.903358, 28.73, 114, "Cd_114"],
                ["Cd", 115.904755, 7.49, 116, "Cd_116"],
                ["Ca", 39.962591, 96.941, 40, "Ca_40"],
                ["Ca", 41.958618, 0.647, 42, "Ca_42"],
                ["Ca", 42.958767, 0.135, 43, "Ca_43"],
                ["Ca", 43.955481, 2.086, 44, "Ca_44"],
                ["Ca", 45.953693, 0.004, 46, "Ca_46"],
                ["Ca", 47.952534, 0.187, 48, "Ca_48"],
                ["C", 12.0, 98.93, 12, "C_12"],
                ["C", 13.003355, 1.07, 13, "C_13"],
                ["Ce", 135.907144, 0.185, 136, "Ce_136"],
                ["Ce", 137.905986, 0.251, 138, "Ce_138"],
                ["Ce", 139.905434, 88.45, 140, "Ce_140"],
                ["Ce", 141.90924, 11.114, 142, "Ce_142"],
                ["Cs", 132.905447, 100.0, 133, "Cs_133"],
                ["Cl", 34.968853, 75.78, 35, "Cl_35"],
                ["Cl", 36.965903, 24.22, 37, "Cl_37"],
                ["Cr", 49.94605, 4.345, 50, "Cr_50"],
                ["Cr", 51.940512, 83.789, 52, "Cr_52"],
                ["Cr", 52.940654, 9.501, 53, "Cr_53"],
                ["Cr", 53.938885, 2.365, 54, "Cr_54"],
                ["Co", 58.9332, 100.0, 59, "Co_59"],
                ["Cu", 62.929601, 69.17, 63, "Cu_63"],
                ["Cu", 64.927794, 30.83, 65, "Cu_65"],
                ["Dy", 155.924278, 0.06, 156, "Dy_156"],
                ["Dy", 157.924405, 0.1, 158, "Dy_158"],
                ["Dy", 159.925194, 2.34, 160, "Dy_160"],
                ["Dy", 160.92693, 18.91, 161, "Dy_161"],
                ["Dy", 161.926795, 25.51, 162, "Dy_162"],
                ["Dy", 162.928728, 24.9, 163, "Dy_163"],
                ["Dy", 163.929171, 28.18, 164, "Dy_164"],
                ["Er", 161.928775, 0.14, 162, "Er_162"],
                ["Er", 163.929197, 1.61, 164, "Er_164"],
                ["Er", 165.93029, 33.61, 166, "Er_166"],
                ["Er", 166.932045, 22.93, 167, "Er_167"],
                ["Er", 167.932368, 26.78, 168, "Er_168"],
                ["Er", 169.93546, 14.93, 170, "Er_170"],
                ["Eu", 150.919846, 47.81, 151, "Eu_151"],
                ["Eu", 152.921226, 52.19, 153, "Eu_153"],
                ["F", 18.998403, 100.0, 19, "F_19"],
                ["Ga", 68.925581, 60.108, 69, "Ga_69"],
                ["Ga", 70.924705, 39.892, 71, "Ga_71"],
                ["Gd", 151.919788, 0.2, 152, "Gd_152"],
                ["Gd", 153.920862, 2.18, 154, "Gd_154"],
                ["Gd", 154.822619, 14.8, 155, "Gd_155"],
                ["Gd", 155.92212, 20.47, 156, "Gd_156"],
                ["Gd", 156.923957, 15.65, 157, "Gd_157"],
                ["Gd", 157.924101, 24.84, 158, "Gd_158"],
                ["Gd", 159.927051, 21.86, 160, "Gd_160"],
                ["Ge", 69.92425, 20.84, 70, "Ge_70"],
                ["Ge", 71.922076, 27.54, 72, "Ge_72"],
                ["Ge", 72.923459, 7.73, 73, "Ge_73"],
                ["Ge", 73.921178, 36.5, 74, "Ge_74"],
                ["Ge", 75.921403, 7.61, 76, "Ge_76"],
                ["Au", 196.966552, 100.0, 197, "Au_197"],
                ["Hf", 173.94004, 0.16, 174, "Hf_174"],
                ["Hf", 175.941402, 5.26, 176, "Hf_176"],
                ["Hf", 176.94322, 18.6, 177, "Hf_177"],
                ["Hf", 177.943698, 27.28, 178, "Hf_178"],
                ["Hf", 178.945815, 13.62, 179, "Hf_179"],
                ["Hf", 179.946549, 35.08, 180, "Hf_180"],
                ["He", 3.016029, 0.000137, 3, "He_3"],
                ["He", 4.002603, 99.999863, 4, "He_4"],
                ["Ho", 164.930319, 100.0, 165, "Ho_165"],
                ["H", 1.007825, 99.9885, 1, "H_1"],
                ["H", 2.014102, 0.115, 2, "H_2"],
                ["In", 112.904061, 4.29, 113, "In_113"],
                ["In", 114.903878, 95.71, 115, "In_115"],
                ["I", 126.904468, 100.0, 127, "I_127"],
                ["Ir", 190.960591, 37.3, 191, "Ir_191"],
                ["Ir", 192.962924, 62.7, 193, "Ir_193"],
                ["Fe", 53.939615, 5.845, 54, "Fe_54"],
                ["Fe", 55.934942, 91.754, 56, "Fe_56"],
                ["Fe", 56.935399, 2.119, 57, "Fe_57"],
                ["Fe", 57.93328, 0.282, 58, "Fe_58"],
                ["Kr", 77.920386, 0.35, 78, "Kr_78"],
                ["Kr", 79.916378, 2.28, 80, "Kr_80"],
                ["Kr", 81.913485, 11.58, 82, "Kr_82"],
                ["Kr", 82.914136, 11.49, 83, "Kr_83"],
                ["Kr", 83.911507, 57.0, 84, "Kr_84"],
                ["Kr", 85.91061, 17.3, 86, "Kr_86"],
                ["La", 137.907107, 0.09, 138, "La_138"],
                ["La", 138.906348, 99.91, 139, "La_139"],
                ["Pb", 203.973029, 1.4, 204, "Pb_204"],
                ["Pb", 205.974449, 24.1, 206, "Pb_206"],
                ["Pb", 206.975881, 22.1, 207, "Pb_207"],
                ["Pb", 207.976636, 52.4, 208, "Pb_208"],
                ["Li", 6.015122, 7.59, 6, "Li_6"],
                ["Li", 7.016004, 92.41, 7, "Li_7"],
                ["Lu", 174.940768, 97.41, 175, "Lu_175"],
                ["Lu", 175.942682, 2.59, 176, "Lu_176"],
                ["Mg", 23.985042, 78.99, 24, "Mg_24"],
                ["Mg", 24.985837, 10.0, 25, "Mg_25"],
                ["Mg", 25.982593, 11.01, 26, "Mg_26"],
                ["Mn", 54.93805, 100.0, 55, "Mn_55"],
                ["Hg", 195.965815, 0.15, 196, "Hg_196"],
                ["Hg", 197.966752, 9.97, 198, "Hg_198"],
                ["Hg", 198.968262, 16.87, 199, "Hg_199"],
                ["Hg", 199.968309, 23.1, 200, "Hg_200"],
                ["Hg", 200.970285, 13.18, 201, "Hg_201"],
                ["Hg", 201.970626, 29.86, 202, "Hg_202"],
                ["Hg", 203.973476, 6.87, 204, "Hg_204"],
                ["Mo", 91.90681, 14.84, 92, "Mo_92"],
                ["Mo", 93.905088, 9.25, 94, "Mo_94"],
                ["Mo", 94.905841, 15.92, 95, "Mo_95"],
                ["Mo", 95.904679, 16.68, 96, "Mo_96"],
                ["Mo", 96.906021, 9.55, 97, "Mo_97"],
                ["Mo", 97.905408, 24.13, 98, "Mo_98"],
                ["Mo", 99.907477, 9.63, 100, "Mo_100"],
                ["Nd", 141.907719, 27.2, 142, "Nd_142"],
                ["Nd", 142.90981, 12.2, 143, "Nd_143"],
                ["Nd", 143.910083, 23.8, 144, "Nd_144"],
                ["Nd", 144.912569, 8.3, 145, "Nd_145"],
                ["Nd", 145.913112, 17.2, 146, "Nd_146"],
                ["Nd", 147.916889, 5.7, 148, "Nd_148"],
                ["Nd", 149.920887, 5.6, 150, "Nd_150"],
                ["Ne", 19.99244, 90.48, 20, "Ne_20"],
                ["Ne", 20.993847, 0.27, 21, "Ne_21"],
                ["Ne", 21.991386, 9.25, 22, "Ne_22"],
                ["Ni", 57.935348, 68.0769, 58, "Ni_58"],
                ["Ni", 59.930791, 26.2231, 60, "Ni_60"],
                ["Ni", 60.93106, 1.1399, 61, "Ni_61"],
                ["Ni", 61.928349, 3.6345, 62, "Ni_62"],
                ["Ni", 63.92797, 0.9256, 64, "Ni_64"],
                ["Nb", 92.906378, 100.0, 93, "Nb_93"],
                ["N", 14.003074, 99.632, 14, "N_14"],
                ["N", 15.000109, 0.368, 15, "N_15"],
                ["Os", 183.952491, 0.02, 184, "Os_184"],
                ["Os", 185.953838, 1.59, 186, "Os_186"],
                ["Os", 186.955748, 1.96, 187, "Os_187"],
                ["Os", 187.955836, 13.24, 188, "Os_188"],
                ["Os", 188.958145, 16.15, 189, "Os_189"],
                ["Os", 189.958445, 26.26, 190, "Os_190"],
                ["Os", 191.961479, 40.78, 192, "Os_192"],
                ["O", 15.994915, 99.757, 16, "O_16"],
                ["O", 16.999132, 0.038, 17, "O_17"],
                ["O", 17.99916, 0.205, 18, "O_18"],
                ["Pd", 101.905608, 1.02, 102, "Pd_102"],
                ["Pd", 103.904035, 11.14, 104, "Pd_104"],
                ["Pd", 104.905084, 22.33, 105, "Pd_105"],
                ["Pd", 105.903483, 27.33, 106, "Pd_106"],
                ["Pd", 107.903894, 26.46, 108, "Pd_108"],
                ["Pd", 109.905152, 11.72, 110, "Pd_110"],
                ["P", 30.973762, 100.0, 31, "P_31"],
                ["Pt", 189.95993, 0.014, 190, "Pt_190"],
                ["Pt", 191.961035, 0.782, 192, "Pt_192"],
                ["Pt", 193.962664, 32.967, 194, "Pt_194"],
                ["Pt", 194.964774, 33.832, 195, "Pt_195"],
                ["Pt", 195.964935, 25.242, 196, "Pt_196"],
                ["Pt", 197.967876, 7.163, 198, "Pt_198"],
                ["K", 38.963707, 93.2581, 39, "K_39"],
                ["K", 39.963999, 0.0117, 40, "K_40"],
                ["K", 40.961826, 6.7302, 41, "K_41"],
                ["Pr", 140.907648, 100.0, 141, "Pr_141"],
                ["Re", 184.952956, 37.4, 185, "Re_185"],
                ["Re", 186.955751, 62.6, 187, "Re_187"],
                ["Rh", 102.905504, 100.0, 103, "Rh_103"],
                ["Rb", 84.911789, 72.17, 85, "Rb_85"],
                ["Rb", 86.909183, 27.83, 87, "Rb_87"],
                ["Ru", 95.907598, 5.54, 96, "Ru_96"],
                ["Ru", 97.905287, 1.87, 98, "Ru_98"],
                ["Ru", 98.905939, 12.76, 99, "Ru_99"],
                ["Ru", 99.90422, 12.6, 100, "Ru_100"],
                ["Ru", 100.905582, 17.06, 101, "Ru_101"],
                ["Ru", 101.90435, 31.55, 102, "Ru_102"],
                ["Ru", 103.90543, 18.62, 104, "Ru_104"],
                ["Sm", 143.911995, 3.07, 144, "Sm_144"],
                ["Sm", 146.914893, 14.99, 147, "Sm_147"],
                ["Sm", 147.914818, 11.24, 148, "Sm_148"],
                ["Sm", 148.91718, 13.82, 149, "Sm_149"],
                ["Sm", 149.917271, 7.38, 150, "Sm_150"],
                ["Sm", 151.919728, 26.75, 152, "Sm_152"],
                ["Sm", 153.922205, 22.75, 154, "Sm_154"],
                ["Sc", 44.95591, 100.0, 45, "Sc_45"],
                ["Se", 73.922477, 0.89, 74, "Se_74"],
                ["Se", 75.919214, 9.37, 76, "Se_76"],
                ["Se", 76.919915, 7.63, 77, "Se_77"],
                ["Se", 77.91731, 23.77, 78, "Se_78"],
                ["Se", 79.916522, 49.61, 80, "Se_80"],
                ["Se", 81.9167, 8.73, 82, "Se_82"],
                ["Si", 27.976927, 92.2297, 28, "Si_28"],
                ["Si", 28.976495, 4.6832, 29, "Si_29"],
                ["Si", 29.97377, 3.0872, 30, "Si_30"],
                ["Ag", 106.905093, 51.839, 107, "Ag_107"],
                ["Ag", 108.904756, 48.161, 109, "Ag_109"],
                ["Na", 22.98977, 100.0, 23, "Na_23"],
                ["Sr", 83.913425, 0.56, 84, "Sr_84"],
                ["Sr", 85.909262, 9.86, 86, "Sr_86"],
                ["Sr", 86.908879, 7.0, 87, "Sr_87"],
                ["Sr", 87.905614, 82.58, 88, "Sr_88"],
                ["S", 31.972071, 94.93, 32, "S_32"],
                ["S", 32.971458, 0.76, 33, "S_33"],
                ["S", 33.967867, 4.29, 34, "S_34"],
                ["S", 35.967081, 0.02, 36, "S_36"],
                ["Ta", 179.947466, 0.012, 180, "Ta_180"],
                ["Ta", 180.947996, 99.988, 181, "Ta_181"],
                ["Te", 119.90402, 0.09, 120, "Te_120"],
                ["Te", 121.903047, 2.55, 122, "Te_122"],
                ["Te", 122.904273, 0.89, 123, "Te_123"],
                ["Te", 123.902819, 4.74, 124, "Te_124"],
                ["Te", 124.904425, 7.07, 125, "Te_125"],
                ["Te", 125.903306, 18.84, 126, "Te_126"],
                ["Te", 127.904461, 31.74, 128, "Te_128"],
                ["Te", 129.906223, 34.08, 130, "Te_130"],
                ["Tb", 158.925343, 100.0, 159, "Tb_159"],
                ["Tl", 202.972329, 29.524, 203, "Tl_203"],
                ["Tl", 204.974412, 70.476, 205, "Tl_205"],
                ["Th", 232.03805, 100.0, 232, "Th_232"],
                ["Tm", 168.934211, 100.0, 169, "Tm_169"],
                ["Sn", 111.904821, 0.97, 112, "Sn_112"],
                ["Sn", 113.902782, 0.66, 114, "Sn_114"],
                ["Sn", 114.903346, 0.34, 115, "Sn_115"],
                ["Sn", 115.901744, 14.54, 116, "Sn_116"],
                ["Sn", 116.902954, 7.68, 117, "Sn_117"],
                ["Sn", 117.901606, 24.22, 118, "Sn_118"],
                ["Sn", 118.903309, 8.59, 119, "Sn_119"],
                ["Sn", 119.902197, 32.58, 120, "Sn_120"],
                ["Sn", 121.90344, 4.63, 122, "Sn_122"],
                ["Sn", 123.905275, 5.79, 124, "Sn_124"],
                ["Ti", 45.952629, 8.25, 46, "Ti_46"],
                ["Ti", 46.951764, 7.44, 47, "Ti_47"],
                ["Ti", 47.947871, 73.72, 48, "Ti_48"],
                ["W", 179.946706, 0.12, 180, "W_180"],
                ["W", 181.948206, 26.5, 182, "W_182"],
                ["W", 182.950224, 14.31, 183, "W_183"],
                ["W", 183.950933, 30.64, 184, "W_184"],
                ["W", 185.954362, 28.43, 186, "W_186"],
                ["U", 234.040946, 0.0055, 234, "U_234"],
                ["U", 235.043923, 0.72, 235, "U_235"],
                ["U", 238.050783, 99.2745, 238, "U_238"],
                ["V", 49.947163, 0.25, 50, "V_50"],
                ["V", 50.943964, 99.75, 51, "V_51"],
                ["Xe", 123.905896, 0.09, 124, "Xe_124"],
                ["Xe", 125.904269, 0.09, 126, "Xe_126"],
                ["Xe", 127.90353, 1.92, 128, "Xe_128"],
                ["Xe", 128.904779, 26.44, 129, "Xe_129"],
                ["Xe", 129.903508, 10.44, 130, "Xe_130"],
                ["Xe", 130.905082, 21.18, 131, "Xe_131"],
                ["Xe", 131.904154, 26.89, 132, "Xe_132"],
                ["Xe", 133.905395, 10.44, 134, "Xe_134"],
                ["Xe", 135.90722, 8.87, 136, "Xe_136"],
                ["Yb", 167.933894, 0.13, 168, "Yb_168"],
                ["Yb", 169.934759, 3.04, 170, "Yb_170"],
                ["Yb", 170.936322, 14.28, 171, "Yb_171"],
                ["Yb", 171.936378, 21.83, 172, "Yb_172"],
                ["Yb", 172.938207, 16.13, 173, "Yb_173"],
                ["Yb", 173.938858, 31.83, 174, "Yb_174"],
                ["Yb", 175.942568, 12.76, 176, "Yb_176"],
                ["Y", 88.905848, 100.0, 89, "Y_89"],
                ["Zn", 63.929147, 48.63, 64, "Zn_64"],
                ["Zn", 65.926037, 27.9, 66, "Zn_66"],
                ["Zn", 66.927131, 4.1, 67, "Zn_67"],
                ["Zn", 67.924848, 18.75, 68, "Zn_68"],
                ["Zn", 69.925325, 0.62, 70, "Zn_70"],
                ["Zr", 89.904704, 51.45, 90, "Zr_90"],
                ["Zr", 90.905645, 11.22, 91, "Zr_91"],
                ["Zr", 91.90504, 17.15, 92, "Zr_92"],
                ["Zr", 93.906316, 17.38, 94, "Zr_94"],
                ["Zr", 95.908276, 2.8, 96, "Zr_96"]])
    
def ChooseColor(row):
    """
    Придает формуле цвет на диаграмме Ван-Кревелина.
    """
    if "N" in row:
        if "S" in row:
            if row["S"] != 0:
                return "red" if row["N"] != 0 else "green"
            else:
                return "orange" if row["N"] != 0 else "blue"
        else:
            return "orange" if row["N"] != 0 else "blue"
    else:
        return "blue"

def vk(spec: pd.DataFrame,
               ax=None,
               sizes=(7, 30),
               plot_type='default',
               color_palette='viridis',
               error_type='rel_error'):
    """
    Возвращает диаграмму Ван-Кревелена для подставленного спектра.
    
    Parameters
    ----------
    spec : pd.DataFrame
        DataFrame с данными спектра
    ax : matplotlib.axes.Axes, optional
        Оси для отрисовки, если None - создаются новые
    sizes : tuple, optional
        Размеры точек для scatter plot
    plot_type : str, optional
        Тип визуализации:
        - 'default': базовый scatter plot (по умолчанию)
        - 'heatmap': тепловая карта интенсивности
        - 'scatter': точечная карта интенсивности
        - 'error_scatter': точечная карта ошибки
        - 'error_heatmap': тепловая карта ошибки
        - 'mass_scatter': точечная карта масс
        - 'mass_heatmap': тепловая карта масс
        - 'oxygen_scatter': точечная карта количества кислорода
        - 'oxygen_heatmap': тепловая карта количества кислорода
    color_palette : str, optional
        Цветовая палитра для тепловой карты
    error_type : str, optional
        Тип ошибки для визуализации: 'rel_error' или 'abs_error'
    
    Returns
    -------
    matplotlib.axes.Axes
    """
    spec = spec.copy(deep=True)
    
    # Добавляем соотношения O/C и H/C если их нет
    if "O/C" not in list(spec.columns):
        spec["O/C"] = spec["O"] / spec["C"]
        spec["H/C"] = spec["H"] / spec["C"]
    
    # Создаем оси если не переданы
    if ax is None:
        fig, ax = plt.subplots(1, 1, figsize=(6, 6))
        ax.set_xlim((0.0, 1.0))
        ax.set_ylim((0.0, 2.2))
        ax.set_title(f"{spec.attrs['name']}, {spec.dropna().shape[0]} formulas")
    
    # Базовый вариант (оригинальный)
    if plot_type == 'default':
        spec["Color value"] = spec.apply(lambda x: ChooseColor(x), axis=1)
        sns.scatterplot(data=spec, x="O/C", y="H/C", 
                       hue="Color value", hue_order=["blue","orange","green","red"], 
                       size="intensity", alpha=0.7, legend=False, 
                       sizes=sizes, ax=ax)
    
    # Тепловая карта интенсивности
    elif plot_type == 'heatmap':
        valid_data = spec.dropna(subset=['O/C', 'H/C', 'intensity'])
        
        x_bins = np.linspace(0, 1, 50)
        y_bins = np.linspace(0, 2.2, 50)
        
        heatmap, xedges, yedges = np.histogram2d(
            valid_data['O/C'], 
            valid_data['H/C'], 
            bins=[x_bins, y_bins],
            weights=valid_data['intensity']
        )
        
        if heatmap.max() > 0:
            heatmap = heatmap / heatmap.max()
        
        im = ax.imshow(heatmap.T, 
                      extent=(0, 1, 0, 2.2), 
                      origin='lower', 
                      aspect='auto',
                      cmap=color_palette,
                      alpha=0.8)
        
        plt.colorbar(im, ax=ax, label='Normalized Intensity')
        ax.contour(heatmap.T, levels=5, extent=(0, 1, 0, 2.2), 
                  colors='white', alpha=0.5, linewidths=0.5)
    
    # Точечная карта интенсивности
    elif plot_type == 'scatter':
        valid_data = spec.dropna(subset=['O/C', 'H/C', 'intensity'])
        
        intensities = valid_data['intensity']
        if intensities.max() > intensities.min():
            normalized_sizes = (intensities - intensities.min()) / (intensities.max() - intensities.min())
            point_sizes = sizes[0] + normalized_sizes * (sizes[1] - sizes[0])
        else:
            point_sizes = [sizes[0]] * len(intensities)
        
        scatter = ax.scatter(valid_data['O/C'], valid_data['H/C'],
                           c=valid_data['intensity'],
                           s=point_sizes,
                           alpha=0.7,
                           cmap=color_palette)
        
        plt.colorbar(scatter, ax=ax, label='Intensity')
    
    # Точечная карта ошибки
    elif plot_type == 'error_scatter':
        valid_data = spec.dropna(subset=['O/C', 'H/C', error_type])
        
        errors = valid_data[error_type]
        if errors.max() > errors.min():
            normalized_sizes = (errors - errors.min()) / (errors.max() - errors.min())
            point_sizes = sizes[0] + normalized_sizes * (sizes[1] - sizes[0])
        else:
            point_sizes = [sizes[0]] * len(errors)
        
        scatter = ax.scatter(valid_data['O/C'], valid_data['H/C'],
                           c=valid_data[error_type],
                           s=point_sizes,
                           alpha=0.7,
                           cmap=color_palette)
        
        error_label = 'Relative Error (ppm)' if error_type == 'rel_error' else 'Absolute Error'
        plt.colorbar(scatter, ax=ax, label=error_label)
        ax.set_title(f"{spec.attrs['name']} - {error_label}")
    
    # Тепловая карта ошибки
    elif plot_type == 'error_heatmap':
        valid_data = spec.dropna(subset=['O/C', 'H/C', error_type])
        
        x_bins = np.linspace(0, 1, 50)
        y_bins = np.linspace(0, 2.2, 50)
        
        heatmap, xedges, yedges = np.histogram2d(
            valid_data['O/C'], 
            valid_data['H/C'], 
            bins=[x_bins, y_bins],
            weights=valid_data[error_type]
        )
        
        # Для ошибки лучше использовать инверсную палитру - меньшие ошибки лучше
        im = ax.imshow(heatmap.T, 
                      extent=(0, 1, 0, 2.2), 
                      origin='lower', 
                      aspect='auto',
                      cmap=color_palette + '_r',  # инверсная палитра
                      alpha=0.8)
        
        error_label = 'Relative Error (ppm)' if error_type == 'rel_error' else 'Absolute Error'
        plt.colorbar(im, ax=ax, label=error_label)
        ax.set_title(f"{spec.attrs['name']} - {error_label}")
    
    # Точечная карта масс
    elif plot_type == 'mass_scatter':
        valid_data = spec.dropna(subset=['O/C', 'H/C', 'mass'])
        
        masses = valid_data['mass']
        if masses.max() > masses.min():
            normalized_sizes = (masses - masses.min()) / (masses.max() - masses.min())
            point_sizes = sizes[0] + normalized_sizes * (sizes[1] - sizes[0])
        else:
            point_sizes = [sizes[0]] * len(masses)
        
        scatter = ax.scatter(valid_data['O/C'], valid_data['H/C'],
                           c=valid_data['mass'],
                           s=point_sizes,
                           alpha=0.7,
                           cmap=color_palette)
        
        plt.colorbar(scatter, ax=ax, label='Mass')
        ax.set_title(f"{spec.attrs['name']} - Mass Distribution")
    
    # Тепловая карта масс
    elif plot_type == 'mass_heatmap':
        valid_data = spec.dropna(subset=['O/C', 'H/C', 'mass'])
        
        x_bins = np.linspace(0, 1, 50)
        y_bins = np.linspace(0, 2.2, 50)
        
        heatmap, xedges, yedges = np.histogram2d(
            valid_data['O/C'], 
            valid_data['H/C'], 
            bins=[x_bins, y_bins],
            weights=valid_data['mass']
        )
        
        im = ax.imshow(heatmap.T, 
                      extent=(0, 1, 0, 2.2), 
                      origin='lower', 
                      aspect='auto',
                      cmap=color_palette,
                      alpha=0.8)
        
        plt.colorbar(im, ax=ax, label='Average Mass')
        ax.set_title(f"{spec.attrs['name']} - Mass Distribution")
    
    # Точечная карта количества кислорода
    elif plot_type == 'oxygen_scatter':
        valid_data = spec.dropna(subset=['O/C', 'H/C', 'O'])
        
        oxygen_counts = valid_data['O']
        if oxygen_counts.max() > oxygen_counts.min():
            normalized_sizes = (oxygen_counts - oxygen_counts.min()) / (oxygen_counts.max() - oxygen_counts.min())
            point_sizes = sizes[0] + normalized_sizes * (sizes[1] - sizes[0])
        else:
            point_sizes = [sizes[0]] * len(oxygen_counts)
        
        scatter = ax.scatter(valid_data['O/C'], valid_data['H/C'],
                           c=valid_data['O'],
                           s=point_sizes,
                           alpha=0.7,
                           cmap=color_palette)
        
        plt.colorbar(scatter, ax=ax, label='Oxygen Count')
        ax.set_title(f"{spec.attrs['name']} - Oxygen Distribution")
    
    # Тепловая карта количества кислорода
    elif plot_type == 'oxygen_heatmap':
        valid_data = spec.dropna(subset=['O/C', 'H/C', 'O'])
        
        x_bins = np.linspace(0, 1, 50)
        y_bins = np.linspace(0, 2.2, 50)
        
        heatmap, xedges, yedges = np.histogram2d(
            valid_data['O/C'], 
            valid_data['H/C'], 
            bins=[x_bins, y_bins],
            weights=valid_data['O']
        )
        
        im = ax.imshow(heatmap.T, 
                      extent=(0, 1, 0, 2.2), 
                      origin='lower', 
                      aspect='auto',
                      cmap=color_palette,
                      alpha=0.8)
        
        plt.colorbar(im, ax=ax, label='Average Oxygen Count')
        ax.set_title(f"{spec.attrs['name']} - Oxygen Distribution")
    
    else:
        raise ValueError(f"Unknown plot_type: {plot_type}. Available options: 'default', 'heatmap', 'scatter', 'error_scatter', 'error_heatmap', 'mass_scatter', 'mass_heatmap', 'oxygen_scatter', 'oxygen_heatmap'")
    
    # Общие настройки для всех типов графиков
    ax.set_xlabel('O/C')
    ax.set_ylabel('H/C')
    ax.grid(True, alpha=0.3)
    
    # Устанавливаем пределы если они не были установлены ранее
    if ax.get_xlim() == (0.0, 1.0):
        ax.set_xlim(0.0, 1.0)
    if ax.get_ylim() == (0.0, 1.0):
        ax.set_ylim(0.0, 2.2)
    
    return ax
        
def spectrum(spec: pd.DataFrame,
             ax = None):
    
    spec = spec.copy(deep=True)
    
    if ax is None:

        fig, ax = plt.subplots(1,1,figsize=(6,6))
    
    ax.plot(spec["mass"],spec["intensity"], color="black",linewidth=0.2)
        
    ax.set_xlabel("m/z")
    ax.set_ylabel("intensity")
        
    ax.set_xlim((200,1000))

def recallibrate(spec: pd.DataFrame, 
                error_table: Optional[pd.DataFrame] = None, 
                how: str = 'assign',
                mode: str = '-',
                draw: bool = True) -> pd.DataFrame:
    '''
    Recallibrate spectrum

    Fine reccalabration based on self (assign or mass differnce map)
    or with external ethalon spectrum

    Parameters
    ----------
    spec: pd.DataFrame object
        Mass spectrum for recallibration
    error_table: ErrorTable object
        Optional. If None - calculate for spec. 
        ErrorTable object contain table error in ppm for mass, default 100 string            
    how: {'assign', 'mdm', filename} 
        Optional. Default 'assign'.
        If error_table is None we can choose how to recalculate.
        'assign' - by assign error, default.
        'mdm' - by calculation mass-difference map.
        filename - path to etalon spectrum, treated and saved by nomspectra
    mode: str
        Optional. Default '-' negative mode. May be +, - or 0
    draw: bool
        Plot error (fit of KDM)

    Returns
    -------
    pd.DataFrame
    '''

    spec = spec.copy()

    if error_table is None:
        if how == 'assign':
            error_table = assign_error(spec, show_map=draw, mode=mode)
        elif how == 'mdm':
            error_table = massdiff_error(spec, show_map=draw)
        else:
            etalon = read_mass_list(how)
            error_table = etalon_error(spec=spec, etalon=etalon, show_map=draw)

    err = error_table.copy(deep=True)
    spec = spec.reset_index(drop=True)
    wide = len(err)

    min_mass = err['mass'].min()
    max_mass = err['mass'].max()
    a = np.linspace(min_mass, max_mass, wide+1)

    for i in range(wide):
        for ind in spec.loc[(spec['mass']>a[i]) & (spec['mass']<=a[i+1])].index:
            mass = spec.loc[ind, 'mass']
            e = mass * err.loc[i, 'ppm'] / 1000000
            spec.loc[ind, 'mass'] = spec.loc[ind, 'mass'] + e

    spec.attrs['recallibrate'] = how

    return spec

@staticmethod
def md_error_map(
    spec: pd.DataFrame, 
    ppm: float = 3
    ) -> pd.DataFrame:
    '''
    Calculate mass differnce map

    Parameters
    ----------
    spec: pd.DataFrame
        data
    ppm: float
        Optional. Default 3.
        Permissible error in ppm
    show_map: bool
        Optional. Default False.
        Show error in ppm versus mass

    Return
    ------
    Pandas Dataframe
    '''

    #common neutral mass loses: CH2, CO, CH2O, C2HO, H2O, CO2
    df = pd.DataFrame({ 'C':[1,1,1,2,0,1],
                        'H':[2,0,2,1,2,0],
                        'O':[0,1,1,1,1,2]})

    dif_masses = gen_from_brutto(df)['calc_mass'].values.astype('float')
    dif = np.unique([dif_masses*i for i in range(1,10)])

    data = copy.deepcopy(spec)
    masses = data['mass'].values.astype('float')

    data = data.sort_values(by='intensity', ascending=False).reset_index(drop=True)
    if len(data) > 1000:
        data = data[:1000]
    data = data.sort_values(by='mass').reset_index(drop=True)

    data_error = [] #array for new data

    for index, row in data.iterrows(): #take every mass in list
        
        mass = row["mass"]

        for i in dif:
            mz = mass + i #massdif

            idx = np.searchsorted(masses, mz, side='left')                
            if idx > 0 and (idx == len(masses) or np.fabs(mz - masses[idx - 1]) < np.fabs(mz - masses[idx])):
                idx -= 1

            if np.fabs(masses[idx] - mz) / mz * 1e6 <= ppm:
                data_error.append([mass, (masses[idx] - mz)/mz*1000000])
    
    df_error = pd.DataFrame(data = data_error, columns=['mass', 'ppm' ])

    return df_error

@staticmethod
def fit_kernel(
    f: np.ndarray,
    mass: np.ndarray,
    err_ppm: float = 3,
    show_map: bool = True) -> pd.DataFrame:
    '''
    Fit max intesity of kernel density map

    Parameters
    ----------
    f: np.array
        keerndel density map in numpy array 100*100
    show_map: bool
        Optional. Default true.
        Plot how fit kernel

    Return
    ------
    Pandas Dataframe
    '''

    df = pd.DataFrame(f, index=np.linspace(err_ppm,-err_ppm,100))

    out = []
    for i in df.columns:
        max_kernel = df[i].quantile(q=0.95)
        ppm = df.loc[df[i] > max_kernel].index.values
        out.append([i, np.mean(ppm)])
    kde_err = pd.DataFrame(data=out, columns=['i','ppm'])
    
    #smooth data
    kde_err['ppm'] = savgol_filter(kde_err['ppm'], 31,3)
    
    xmin = min(mass)
    xmax = max(mass)
    
    kde_err['mass'] = np.linspace(xmin, xmax, 100)

    ymin = -err_ppm
    ymax = err_ppm

    if show_map:
        fig = plt.figure(figsize=(4,4), dpi=75)
        ax = fig.gca()
        ax.set_xlim(xmin, xmax)
        ax.set_ylim(ymin, ymax)
        ax.imshow(df, extent=(xmin, xmax, ymin, ymax), aspect='auto')
        ax.plot(kde_err['mass'], kde_err['ppm'], c='r')
        ax.set_xlabel('m/z, Da')
        ax.set_ylabel('error, ppm')      

    return kde_err

@staticmethod
def kernel_density_map(
    df_error: pd.DataFrame, 
    ppm: float = 3, 
    ) -> np.ndarray:
    '''
    Calculate and plot kernel density map 100*100 for data

    Parameters
    ----------
    df_error: pd.Dataframe
        error_table for generate kerle density map
    ppm: float
        Optional. Default 3.
        treshould for generate
    show_map: bool
        Optional. Default False. plot kde

    Return
    ------
    numpy array
    '''
    
    x = np.array(df_error['mass'])
    y = np.array(df_error['ppm'])

    xmin = min(x) 
    xmax = max(x) 

    ymin = -ppm 
    ymax = ppm 

    xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]

    positions = np.vstack([xx.ravel(), yy.ravel()])
    values = np.vstack([x, y])
    kernel = st.gaussian_kde(values)
    kdm = np.reshape(kernel(positions).T, xx.shape)
    kdm = np.rot90(kdm)
    
    return kdm

@staticmethod
def assign_error(
    spec: pd.DataFrame,
    ppm: float = 3,
    brutto_dict = {'C':(4,30), 'H':(4,60), 'O':(0,20)},
    mode = '-',
    show_map: bool = True):
    '''
    Recallibrate by assign error

    Parameters
    ----------
    spec: pd.DataFrame object
        Initial mass spectrum for recallibrate
    ppm: float
        Permissible relative error in callibrate error. Default 3.
    brutto_dict: dict
        Dictonary with elements ranges for assignment
    mode: str
        Optional. Default '-' negative mode. May be +, - or 0
    show_error: bool
        Optional. Default True. Show process 

    Return
    ------
    ErrorTable
    '''

    spectr = copy.deepcopy(spec)
    spectr = assign(spectr,rel_error=ppm, brutto_dict=brutto_dict, sign=mode)
    spectr = calc_error(calc_mass(spectr))

    error_table = spectr
    error_table = error_table.loc[:,['mass','rel_error']]
    error_table.columns = ['mass', 'ppm']
    error_table['ppm'] = - error_table['ppm']
    error_table = error_table.dropna()

    kdm = kernel_density_map(df_error = error_table)
    err = fit_kernel(f=kdm, 
                        show_map=show_map, 
                        mass=drop_unassigned(spectr)['mass'].values)
    err = extrapolate(err,(spec['mass'].min(), spec['mass'].max()))

    return err

@staticmethod
def massdiff_error( spec: pd.DataFrame,
                    show_map:bool = True):
    '''
    Self-recallibration of mass-spectra by mass-difference map

    Parameters
    -----------
    spec: pd.DataFrame object
        Initial mass spectrum for recallibrate
    show_error: bool
        Optional. Default True. Show process 

    Return
    -------
    ErrorTable

    References
    ----------
    Smirnov, K. S., Forcisi, S., Moritz, F., Lucio, M., & Schmitt-Kopplin, P. 
    (2019). Mass difference maps and their application for the 
    recalibration of mass spectrometric data in nontargeted metabolomics. 
    Analytical chemistry, 91(5), 3350-3358. 
    '''

    spec = copy.deepcopy(spec)
    mde = md_error_map(spec = spec)
    kdm = kernel_density_map(df_error=mde)
    err = fit_kernel(f=kdm, show_map=show_map, mass=spec['mass'].values)
    
    err['ppm'] = err['ppm'] - err.loc[0, 'ppm']

    return err

@staticmethod
def etalon_error(spec: pd.DataFrame,
                etalon: pd.DataFrame,
                quart: float = 0.9,
                ppm: float = 3,
                show_map: bool = True): 
    '''
    Recallibrate by etalon

    Parameters
    ----------
    spec: pd.DataFrame object
        Initial mass spectrum for recallibrate
    etalon: pd.DataFrame object
        Etalon mass spectrum
    quart: float
        Optionaly. by default it is 0.9. 
        Usualy it is enough for good callibration
        Quartile, which will be taken for calc recallibrate error
    ppm: float
        Optionaly. Default 3.
        permissible relative error in ppm for seak peak in etalon
    show_map: bool
        Optional. Default True. Show process 

    Return
    ------
    ErrorTable
    '''

    et = etalon['mass'].values.astype('float')  # Используем numpy array вместо list
    df = spec.copy()  # Простое копирование вместо deepcopy

    # Фильтрация по квантилю
    treshold = df['intensity'].quantile(quart)
    df_filtered = df[df['intensity'] > treshold].copy()
    
    # Векторизованное вычисление границ
    min_masses = df_filtered['mass'].values.astype('float') * (1 - ppm / 1000000)
    max_masses = df_filtered['mass'].values.astype('float') * (1 + ppm / 1000000)
    
    # Преобразуем etalon в отсортированный numpy array для бинарного поиска
    et_sorted = np.sort(et)
    
    # Функция для поиска ближайшего эталонного значения в пределах ppm
    def find_closest_etalon(mass, min_mass, max_mass):
        # Бинарный поиск в отсортированном массиве
        idx = np.searchsorted(et_sorted, min_mass)
        if idx < len(et_sorted) and et_sorted[idx] <= max_mass:
            return et_sorted[idx]
        return 0
    
    # Векторизованное применение функции
    df_filtered['cal'] = np.vectorize(find_closest_etalon, otypes=[float])(
        df_filtered['mass'].values, min_masses, max_masses
    )
    
    # Альтернативный вариант с использованием broadcasting (быстрее для больших данных)
    # df_filtered['cal'] = 0
    # for i, (min_m, max_m) in enumerate(zip(min_masses, max_masses)):
    #     mask = (et_sorted >= min_m) & (et_sorted <= max_m)
    #     if np.any(mask):
    #         df_filtered.iloc[i, df_filtered.columns.get_loc('cal')] = et_sorted[mask][0]

    # Фильтрация и вычисления
    df_calibrated = df_filtered[df_filtered['cal'] > 0].copy()
    df_calibrated['dif'] = df_calibrated['cal'] - df_calibrated['mass']
    df_calibrated['ppm'] = df_calibrated['dif'] / df_calibrated['mass'] * 1000000
    
    error_table = df_calibrated[['mass', 'ppm']].dropna()
    
    kdm = kernel_density_map(df_error=error_table)
    err = fit_kernel(f=kdm, show_map=show_map, mass=spec['mass'].values)

    return err

def extrapolate(self, ranges:Optional[Tuple[float, float]] = None) -> pd.DataFrame:
    """
    Extrapolate error data

    Parameters
    ----------
    ranges: Tuple(numeric, numeric)
        Optionaly. Default None - all width of mass in error table.
        For which diaposone of mass extrapolate data

    Return
    ------
    ErrorTable
    """
    
    if ranges is None:
        ranges = (self['mass'].min(), self['mass'].max())

    interpolation_range = np.linspace(ranges[0], ranges[1], 100)
    linear_interp = CubicSpline(self['mass'], self['ppm'], extrapolate=True)
    linear_results = linear_interp(interpolation_range)
    err = pd.DataFrame()
    err ['mass'] = interpolation_range
    err ['ppm'] = linear_results

    return err

def show_error(self) -> None:
    """
    Plot error map from ErrorTable class data
    """

    fig, ax = plt.subplots(figsize=(4,4), dpi=75)
    ax.plot(self['mass'], self['ppm'])
    ax.set_xlabel('m/z, Da')
    ax.set_ylabel('error, ppm')
    
def MolClassesSpectrum(specList,draw=True,ax=None):

    density_class_list=[]
    sample_list = []
    for i in range(len(specList)):
        spec = specList[i]
        data_class = spec.get_mol_class(how="perminova")
        density_class_list.append(data_class["density"])
        sample_list.append(spec.metadata["name"])
        mol_class_list=data_class["class"].to_list()
    mol_class_data = pd.DataFrame(np.array(density_class_list), index=sample_list, columns=mol_class_list) # type: ignore
    df_reversed = mol_class_data.sort_index(ascending=False).copy()
    if ax is None:
        fig, ax = plt.subplots(1,1,figsize=(8, 6))
    df_reversed.plot(kind='barh', stacked=True, ax=ax)
    # Настройки графика
    ax.set_title('Распределение классов по образцам')
    ax.set_xlabel('Доля')
    ax.set_ylabel('Образец')
    #plt.xticks(rotation=30)  # Чтобы подписи по оси X не наклонялись
    ax.legend(title='Классы', bbox_to_anchor=(1.05, 1), loc='upper left')  # Легенда справа
    # Показать график
    plt.tight_layout()

    return df_reversed

def CalcMetricSpectrum(specList,func="weight",draw=True):

    list_data = []
    for i in range(len(specList)):
        spec = specList[i]
        data = spec.get_mol_metrics(func=func)
        data.rename(columns={"value": f"{spec.metadata['name']}"},inplace=True)
        if i == 0:
            data_prev = data
            continue
        else:
            data_prev=data.merge(data_prev, on="metric") # type: ignore

    return data_prev # type: ignore

def FormulaSpecData(specList, draw=True):
    all_formula_list = []
    sample_list = []
    CHON_formula_list = []
    CHOS_formula_list = []
    CHONS_formula_list = []
    dict_list = []
    data = pd.DataFrame()
    for i in range(len(specList)):
        spec = specList[i]

        sample_list.append(spec.metadata["name"])

        all_formula_list.append(spec.table.dropna().shape[0])

        dict = spec.table[["N","S"]].value_counts().to_dict()

        result_CHON = [key for key in dict.keys() if key[0] > 0 and key[1] < 1]
        result_CHOS = [key for key in dict.keys() if key[0] < 1 and key[1] > 0]
        result_CHONS = [key for key in dict.keys() if key[0] > 0 and key[1] > 0]
        sum_CHON = []
        sum_CHOS = []
        sum_CHONS = []
        for res in result_CHON:
            sum_CHON.append(dict[res])
        for res in result_CHOS:
            sum_CHOS.append(dict[res])
        for res in result_CHONS:
            sum_CHONS.append(dict[res])
        CHON_formula_list.append(sum(sum_CHON))
        CHOS_formula_list.append(sum(sum_CHOS))
        CHONS_formula_list.append(sum(sum_CHONS))
        dict_list.append(dict)
    data["All formulas"] = all_formula_list
    data["CHON, formulas"] = CHON_formula_list
    data["CHOS, formulas"] = CHOS_formula_list
    data["CHONS, formulas"] = CHONS_formula_list
    data["Dict, {N, S}: count"] = dict_list
    data["Sample name"] = sample_list
    data.set_index("Sample name",inplace=True)

    if draw:
        data.plot(kind='bar', stacked=False, figsize=(10, 8))
        plt.xticks(rotation=30)
        plt.tight_layout()
        
    return data

def assign_by_tmds(
    spec: pd.DataFrame, 
    tmds_spec: Optional["pd.DataFrame"] = None,
    tmds_brutto_dict: Optional[Dict] = None, 
    rel_error: float = 3,
    p = 0.2,
    max_num: Optional[int] = None,
    C13_filter: bool = True
    ) -> "pd.DataFrame":
    '''
    Assigne brutto formulas by TMDS

    Additianal assignment of masses that can't be done with usual methods

    Parameters
    ----------
    spec: Spectrum object
        Mass spectrum for assign by tmds
    tmds_spec: Tmds object
        Optional. if None generate tmds spectr with default parameters
        Tmds object, include table with most intensity mass difference
    brutto_dict: dict
        Optional. Deafault None.
        Custom Dictonary for generate brutto table.
        Example: {'C':(-1,20),'H':(-4,40), 'O':(-1,20),'N':(-1,2)}
    abs_error: float
        Optional, default 1 ppm. Relative error for assign peaks by massdif
    p: float
        Optional. Default 0.2. 
        Relative intensity coefficient for treshold tmds spectrum
    max_num: int
        Optional. Max mass diff numbers
    C13_filter: bool
        Use only peaks with C13 isotope peak for generate tmds. Default True.

    Return
    ------
    Spectrum
        Assigned by tmds masses

    Reference
    ---------
    Kunenkov, Erast V., et al. "Total mass difference 
    statistics algorithm: a new approach to identification 
    of high-mass building blocks in electrospray ionization 
    Fourier transform ion cyclotron mass spectrometry data 
    of natural organic matter." 
    Analytical chemistry 81.24 (2009): 10106-10115.
    '''
    
    if "assign" not in spec:
        raise Exception("Spectrum is not assigned")

    spec = spec.copy()

    #calculstae tmds table
    if tmds_spec is None:
        tmds_spec = calc(spec, p=p, C13_filter=C13_filter) #by varifiy p-value we can choose how much mass-diff we will take
        tmds_spec = assign_tmds(tmds_spec,max_num=max_num, brutto_dict=tmds_brutto_dict)
        tmds_spec = calc_mass(tmds_spec)

    #prepare tmds table
    tmds = tmds_spec.sort_values(by='intensity', ascending=False).reset_index(drop=True)
    tmds = tmds.loc[tmds['intensity'] > p].sort_values(by='mass', ascending=True).reset_index(drop=True)
    elem_tmds = find_elements(tmds_spec)

    #prepare spec table
    assign_false = copy.deepcopy(spec.loc[spec['assign'] == False]).reset_index(drop=True)
    assign_true = copy.deepcopy(spec.loc[spec['assign'] == True]).reset_index(drop=True)
    masses = assign_true['mass'].values
    elem_spec = find_elements(spec)
    
    
    #Check that all elements in tmds also in spec
    if len(set(elem_tmds)-set(elem_spec)) > 0:
        raise Exception(f"All elements in tmds spectrum must be in regular spectrum too. But {(set(elem_tmds)-set(elem_spec))} not in spectrum")
    for i in set(elem_spec)-set(elem_tmds):
        tmds[i] = 0

    mass_dif_num = len(tmds)
    masses = np.array(masses)
    min_mass = np.min(masses)

    for i, row_tmds in tqdm(tmds.iterrows(), total=mass_dif_num):

        mass_shift = - row_tmds['calc_mass']
        
        for index, row in assign_false.iterrows():

            if row['assign'] == True:
                continue
                    
            mass = row["mass"] + mass_shift
            if mass < min_mass:
                continue

            idx = np.searchsorted(masses, mass, side='left')
            if idx > 0 and (idx == len(masses) or np.fabs(mass - masses[idx - 1]) < np.fabs(mass - masses[idx])):
                idx -= 1
                
            if np.fabs(masses[idx] - mass) / mass * 1e6 <= rel_error:
                assign_false.loc[pd.Index([index]),'assign'] = True

                for el in elem_spec:
                    assign_false.loc[pd.Index([index]),el] = row_tmds[el] + assign_true.loc[idx,el]

    assign_true = pd.concat([assign_true, assign_false], ignore_index=True).sort_values(by='mass').reset_index(drop=True)
    
    out = calc_mass(assign_true)

    out=out[out['calc_mass'].isnull() | ~out[out['calc_mass'].notnull()].duplicated(subset='calc_mass',keep='first')] 
    spec = out.sort_values(by='mass').reset_index(drop=True)

    
    return spec

def calc(
    self: pd.DataFrame,
    other: Optional["pd.DataFrame"] = None,
    p: float = 0.2,
    wide: int = 10,
    C13_filter:bool = True,
    ) -> "pd.DataFrame":
    """
    Total mass difference statistic calculation 

    Parameters
    ----------
    other: Spectrum object
        Optional. If None, TMDS will call by self.
    p: float
        Minimum relative intensity for taking mass-difference. Default 0.2.
    wide: int
        Minimum interval in 0.001*wide Da of peaks finding. Default 10.
    C13_filter: bool
        Use only peaks that have C13 isotope peak. Default True

    Return
    ------
    pd.DataFrame
    """

    spec = self.copy(deep=True)

    if other is None:
        spec2 = self.copy(deep=True)
    else:
        spec2 = other.copy(deep=True)

    if C13_filter:
        spec = filter_by_C13(spec, remove=True)
        spec2 = filter_by_C13(spec2, remove=True)
    else:
        spec = drop_unassigned(spec)
        spec2 = drop_unassigned(spec2)

    masses = spec['mass'].values
    masses2 = spec2['mass'].values

    mass_num = len(masses)
    mass_num2 = len(masses2)

    if mass_num <2 or mass_num2 < 2:
        raise Exception(f"Too low number of assigned peaks")

    mdiff = np.zeros((mass_num, mass_num2), dtype=float)
    for x in range(mass_num):
        for y in range(x, mass_num2):
            dif = np.fabs(masses[x]-masses2[y])
            if dif < 300:
                mdiff[x,y] = dif

    mdiff = np.round(mdiff, 3)
    unique, counts = np.unique(mdiff, return_counts=True)
    counts[0] = 0

    tmds_spec = pd.DataFrame()
    tmds_spec.attrs['name'] = spec.attrs['name']
    tmds_spec['mass'] = unique
    tmds_spec['count'] = counts
    tmds_spec['intensity'] = tmds_spec['count']/mass_num
    tmds_spec = tmds_spec.sort_values(by='mass').reset_index(drop=True)

    value_zero = set([i/1000 for i in range (0, 300000)]) - set (unique)
    unique = np.append(unique, np.array(list(value_zero)))
    counts = np.append(counts, np.zeros(len(value_zero), dtype=float))

    peaks, properties = find_peaks(tmds_spec['intensity'], distance=wide, prominence=p/2)
    prob = []
    for peak in peaks:
        prob.append(tmds_spec.loc[peak-5:peak+5,'intensity'].sum())
    tmds_spec = tmds_spec.loc[peaks].reset_index(drop=True)
    tmds_spec['intensity'] = prob
    tmds_spec = tmds_spec.loc[tmds_spec['intensity'] > p]

    if len(tmds_spec) < 0:
        raise Exception(f"There isn't mass diff mass, decrease p-value")

    self = tmds_spec

    return self

def calc_by_brutto(self) -> "pd.DataFrame":

    """
    Calculate self difference by calculated mass from brutto

    Return
    ------
    pd.DataFrame
    """
    name = self.attrs['name']
    mass = calc_error(
        drop_unassigned(self)
    )['calc_mass'].values

    massl = len(mass)
    mdiff = np.zeros((massl, massl), dtype=float)
    for x in range(massl):
        for y in range(x, massl):
            mdiff[x,y] = np.fabs(mass[x]-mass[y])

    mdiff = np.round(mdiff, 6)
    unique, counts = np.unique(mdiff, return_counts=True)
    counts[0] = 0

    diff_spec = pd.DataFrame()
    diff_spec['mass'] = unique
    diff_spec['count'] = counts
    diff_spec['intensity'] = diff_spec['count']/massl
    diff_spec = diff_spec.sort_values(by='mass').reset_index(drop=True)

    diff_spec.attrs['name'] = name
    
    self = diff_spec

    return self

def assign_tmds(
    self,
    generated_bruttos_table: Optional[pd.DataFrame] = None,
    error: float = 0.001,
    brutto_dict: Optional[dict] = None,
    max_num: Optional[int] = None
    ) -> "pd.DataFrame":

    """
    Finding the nearest mass in generated_bruttos_table

    Parameters
    ----------
    generated_bruttos_table: pandas DataFrame 
        Optional. with column 'mass' and elements, should be sorted by 'mass'
    error: float
        Optional. Default 0.001. 
        absolute error iin Da for assign formulas
    brutto_dict: dict
        Optional, default {'C':(-1,20),'H':(-4,40), 'O':(-1,20),'N':(-1,2)}
        generate brutto table if generated_bruttos_table is None.
    max_num: int
        Optional. Default 100
    
    Return
    ------
    pd.DataFrame
    """

    if brutto_dict is None:
        brutto_dict = {'C':(-1,20),'H':(-4,40), 'O':(-1,20),'N':(-1,2)}

    if generated_bruttos_table is None:
        generated_bruttos_table = brutto_gen(brutto_dict, rules=False) # type: ignore
        generated_bruttos_table = generated_bruttos_table.loc[generated_bruttos_table['mass'] > 0]

    res = drop_unassigned(assign(self,generated_bruttos_table=generated_bruttos_table, abs_error=error, sign='0'))

    if max_num is not None and len(res) > max_num:
        res = res.sort_values(by='intensity', ascending=False).reset_index(drop=True)
        res = res.loc[:max_num].reset_index(drop=True)
        res = res.sort_values(by='mass').reset_index(drop=True)
    

    return res


def assign_new(data: pd.DataFrame,
            brutto_dict: Any|None = None,
            generated_bruttos_table: Optional[pd.DataFrame] = None,
            rel_error: float|None = None,
            abs_error: float|None = None,
            sign: str ='-',
            mass_min: Optional[float] =  None,
            mass_max: Optional[float] = None,
            intensity_min: Optional[float] =  None,
            intensity_max: Optional[float] = None,
            charge_max: int = 1,
            nitrogen_precision_factor: float = 2.0,
            sulfur_precision_factor: float = 2.0
    ) -> pd.DataFrame:
        """
        Assigning brutto formulas to signal by mass
        
        Parameters
        -----------
        brutto_dict: dict
            Optional. Deafault None.
            Custom Dictonary for generate brutto table.
            Example: {'C':(4, 51),'H':(4, 101),'O':(0,26), 'N':(0,4), 'C_13':(0,3)}
        generated_bruttos_table: pandas DataFrame 
            Optional. Contain column 'mass' and elements, 
            should be sorted by 'mass'.
            Can be generated by function brutto_generator.brutto_gen(). 
            if 'None' generate table with default elemnets and ranges
            C: 4-50, H 4-100, O 0-25, N 0-3, S 0-2.
        rel_error: float
            Optional. default 0.5, permissible error in ppm for assign mass to brutto formulas
        abs_error: float
            Optional. default None, permissible absolute error for assign mass to brutto formulas
        sign: str
            Optional. Deafult '-'.
            Mode in which mass spectrum was gotten. 
            '-' for negative mode
            '+' for positive mode
            '0' for neutral
        mass_min: float
            Optional. Default None. Minimall mass for assigment
        mass_max: float
            Optional. Default None. Maximum mass for assigment
        intensity_min: float
            Optional. Default None. Minimall intensity for assigment
        intensity_max: float
            Optional. Default None. Maximum intensity for assigment
        charge_max: int
            Maximum charge in m/z. Default 1.
        nitrogen_precision_factor: float
            Optional. Default 2.0. Factor by which to increase precision for formulas containing nitrogen
        sulfur_precision_factor: float
            Optional. Default 2.0. Factor by which to increase precision for formulas containing sulfur

        Return
        ------
        pd.DataFrame 
        """

        name = data.attrs['name']

        if generated_bruttos_table is None:
            generated_bruttos_table = brutto_gen(brutto_dict)

        if mass_min is None:
            mass_min = data['mass'].min()
        if mass_max is None:
            mass_max = data['mass'].max()
        if intensity_min is None:
            intensity_min = data['intensity'].min()
        if intensity_max is None:
            intensity_max = data['intensity'].max()
        
        if sign == '-':
            mass_shift = - 0.00054858 + 1.007825  # electron and hydrogen mass
        elif sign == '+':
            mass_shift = 0.00054858  # electron mass
        elif sign == '0':
            mass_shift = 0
        else:
            raise Exception('Sended sign to assign method is not correct. May be "+","-","0"')

        data.attrs['sign'] = sign

        if rel_error is not None and abs_error is not None:
            raise Exception('one of rel_error or abs_error must be None in assign method')
        
        if rel_error is not None:
            rel = True
            
        elif abs_error is not None:
            rel = False
        else:
            rel = True
            rel_error = 0.5

        data = data.loc[:,['mass', 'intensity']].reset_index(drop=True)
        table = data.copy(deep=True)

        masses = np.array(generated_bruttos_table["mass"].values)

        elems = list(generated_bruttos_table.drop(columns=["mass"]))
        bruttos = generated_bruttos_table[elems].values.tolist()

        res = []
        for index, row in table.iterrows():

            if (row["mass"] < mass_min or 
                row["mass"] > mass_max or
                row["intensity"] < intensity_min or 
                row["intensity"] > intensity_max):
                res.append({"assign": False})
                continue 
            
            assigned = False
            for charge in range(1, charge_max + 1):
                mass = (row["mass"] + mass_shift) * charge
                idx = np.searchsorted(masses, mass, side='left')
                if idx > 0 and (idx == len(masses) or np.fabs(mass - masses[idx - 1]) < np.fabs(mass - masses[idx])):
                    idx -= 1

                # Проверяем, содержит ли формула азот или серу
                current_brutto = bruttos[idx]
                has_nitrogen = 'N' in elems and current_brutto[elems.index('N')] > 0
                has_sulfur = 'S' in elems and current_brutto[elems.index('S')] > 0
                
                # Определяем точность для текущей формулы
                if rel:
                    current_error = rel_error
                    if has_nitrogen:
                        current_error = rel_error / nitrogen_precision_factor # type: ignore
                    if has_sulfur:
                        current_error = rel_error / sulfur_precision_factor # type: ignore
                    
                    if np.fabs(masses[idx] - mass) / mass * 1e6 <= current_error/charge: # type: ignore
                        res.append({**dict(zip(elems, bruttos[idx])), "assign": True, "charge": charge})
                        assigned = True
                        break
                else:
                    current_error = abs_error
                    if has_nitrogen:
                        current_error = abs_error / nitrogen_precision_factor  # type: ignore
                    if has_sulfur:
                        current_error = abs_error / sulfur_precision_factor  # type: ignore
                    
                    if np.fabs(masses[idx] - mass) <= current_error/charge: # type: ignore
                        res.append({**dict(zip(elems, bruttos[idx])), "assign": True, "charge": charge})
                        assigned = True
                        break
            
            if not assigned:
                # Если формула с повышенной точностью не приписалась, 
                # ищем следующую подходящую формулу без азота и серы
                for charge in range(1, charge_max + 1):
                    mass = (row["mass"] + mass_shift) * charge
                    idx = np.searchsorted(masses, mass, side='left')
                    
                    # Ищем ближайшие формулы в обе стороны
                    candidates = []
                    if idx > 0:
                        candidates.append(idx - 1)
                    if idx < len(masses):
                        candidates.append(idx)
                    if idx + 1 < len(masses):
                        candidates.append(idx + 1)
                    
                    for candidate_idx in candidates:
                        candidate_brutto = bruttos[candidate_idx]
                        has_nitrogen = 'N' in elems and candidate_brutto[elems.index('N')] > 0
                        has_sulfur = 'S' in elems and candidate_brutto[elems.index('S')] > 0
                        
                        # Используем обычную точность для формул без азота и серы
                        if not has_nitrogen and not has_sulfur:
                            if rel:
                                if np.fabs(masses[candidate_idx] - mass) / mass * 1e6 <= rel_error/charge: # type: ignore
                                    res.append({**dict(zip(elems, bruttos[candidate_idx])), "assign": True, "charge": charge})
                                    assigned = True
                                    break
                            else:
                                if np.fabs(masses[candidate_idx] - mass) <= abs_error/charge: # type: ignore
                                    res.append({**dict(zip(elems, bruttos[candidate_idx])), "assign": True, "charge": charge})
                                    assigned = True
                                    break
                    if assigned:
                        break
            
            if not assigned:
                res.append({"assign": False, "charge": 1})

        res = pd.DataFrame(res)

        table = table.join(res)
        data = data.merge(table, how='outer', on=list(data.columns))
        data['assign'] = data['assign'].fillna(False)
        data['charge'] = data['charge'].fillna(1)
        data.attrs['name'] = name

        return data

if __name__ == '__main__':
    pass